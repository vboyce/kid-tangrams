---
title             : |
  | Preschoolers can coordinate with each other to communicate about novel referents
shorttitle: Preschoolers can coordinate
author: 
  - name          : "Veronica Boyce"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    email         : "vboyce@stanford.edu"
  - name          : "Robert Z. Sparks"
    affiliation   : "1"
  - name          : "Michael C. Frank"
    affiliation   : "1"
    

affiliation:
  - id            : "1"
    institution   : "Stanford University"
  - id            : "1"
    institution   : "Massachusetts Institute of Technology"

authornote: |
  Acknowledgements: We would like to express graditude to all the research assistants who made this work possible: Ilaria Chen, Noah Dang, Hana Doueiri, Benji Fernandez, Gabriella Ignacio, Yannick Mofor, Malia J. Perez, Victoria Phan, Rebecca Pizzitola, and Ania Saucedo. This work would not have been possible without the support of Bing Nursery School. We are grateful to members of the Language and Cognition lab for feedback on earlier versions of this work. 

  Author contributions: All authors contributed to the conceptualization. VB provided methodology, formal analysis, and writing-original draft. RZS provided supervision and project administration. RZS and MCF provided writing-review & editing. 

abstract: |
  Learning language requires learning not only the content of language, but also how to use language to communicate. Iterated reference games provide a window into such skills, requiring rich communication as participants converge on mutually understandable names for initially novel referents. Some early experiments are interpreted as evidence that 4-5-year-old children cannot converge on the mutually understandable names needed to succeed in an iterated reference game. Here, we revisit young children's referential communicative abilities using a simpler, child-friendly paradigm. Across 82 pairs of children (N=158), we found that 4-5-year-olds could successfully establish reference with each other. Children were 81% accurate, and they often used descriptions similar to their partner's. These findings suggest that children’s capacity to construct effective referring expressions in novel contexts emerges earlier than previously thought, consistent with the view that children show early pragmatic competence in supportive contexts.
  

keywords          : development; iterated reference game; pragmatics; preschoolers
wordcount         : "6330"

bibliography      : preschool-tangrams.bib

floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
csl               : apa7.csl
output            : papaja::apa6_pdf
header-includes   :
  - \usepackage{setspace}\singlespacing
  - \setlength{\parskip}{0pt}
---

```{r setup, include = FALSE}
library("papaja")

knitr::opts_chunk$set(
  fig.width = 3, fig.height = 3, fig.crop = F,
  fig.pos = "tb", fig.path = "figs/",
  echo = F, warning = F, cache = F,
  message = F, sanitize = T
)

library(png)
library(grid)
library(ggplot2)
library(xtable)
library(tidyverse)
library(here)
library(brms)
library(rstan)
library(rstanarm)
library(ggthemes)
library(kableExtra)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())

expt_1 <- "data/expt_1"
expt_2 <- "data/expt_2"
expt_3 <- "data/expt_3"
mod_loc <- "code/mods_for_paper"
mod_results <- "code/mods_for_paper/summary"
mod_form <- "code/mods_for_paper/formulae"
time_palette <- c("practice" = "grey", "block 1" = "#E41A1C", "block 2" = "#377EB8", "block 3" = "#4DAF4A", "block 4" = "purple") 

library(ggtext)
labels <- tribble(~target, ~img,
                  "hold", "I1.jpg",
                  "swim", "D1.jpg",
                  "walk", "B1.jpg",
                  "jump", "E1.jpg",
                  "baby","tangram_H.png",
                  "bunny","tangram_E.png",
                  "dancer","tangram_G.png",
                  "zombie", "tangram_A.png"
                  ) |> 
  mutate(img_source= str_c("<img src='",img,"' width='20' />"))

#source(here("code/paper_helper.R"))
joint_data <- read_csv(here("data/processed_for_paper/joint_with_demog.csv"))
joint_similarities <-   read_csv(here("data/processed_for_paper/sims.csv"))

### functions for printing things nicely!
stats <- function(model, row, decimal = 2) {
  model <- model |>
    mutate(
      Estimate = round(Estimate, digits = decimal),
      Lower = round(lower, digits = decimal),
      Upper = round(upper, digits = decimal),
      `Credible Interval` = str_c("[", Lower, ", ", Upper, "]")
    ) |>
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row, 1], ": ", model[row, 2], " ", model[row, 3])
}

stats_text <- function(model, row, decimal = 2) {
  model <- model |>
    mutate(
      Estimate = round(Estimate, digits = decimal) |> formatC(format='f', digits=decimal ),
      Lower = round(lower, digits = decimal) |> formatC(format='f', digits=decimal ),
      Upper = round(upper, digits = decimal) |> formatC(format='f', digits=decimal ),
      `Credible Interval` = str_c("[", Lower, ", ", Upper, "]")
    ) |>
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row, 2], "  ", model[row, 3])
}

form <- function(model_form) {
  dep <- as.character(model_form$formula[2])
  ind <- as.character(model_form$formula[3])
  
  str_c(dep, " ~ ", ind) |>
    str_replace_all(" ", "") |>
    str_replace_all("\\*", " $\\\\times$ ") |>
    str_replace_all("\\+", "&nbsp;+ ") |>
    str_replace_all("~", "$\\\\sim$ ")
}
```

```{r}
# for use in abstract 
pairs <- joint_data |> distinct(game, expt) |> nrow() #82

pct <- joint_data |> summarize(m=round(mean(correct)*100)) |> pluck() #81
```

Learning a language requires learning not only the content of that language, but also how to use the language to communicate. One case study for language use is referential communication, the ability to describe a target so an interlocutor can pick it out from a set of possibilities. Adults show sensitivity to both the visual context and their audience during referential communication, calibrating the description they provide to their beliefs about the interlocutor's knowledge state [@brown-schmidt2018; @galati2010; @hawkins2023chai; @yoon2019contextual]. 

Iterated reference games provide an important paradigm for studying referential communication. In these games, one player repeatedly describes a set of abstract shapes to a partner so they can identify the target images [@clark1986; @krauss1964; @hawkins2020dynamics; @boyce2024]. Over repetition, features of the initial descriptions are conventionalized as each pair comes to agree on a shared understanding of how to label each image. Success at this task requires mastery of a number of linguistic and communicative skills, including producing adequate initial descriptions, monitoring for comprehension, asking for clarification, and appropriately using the shared conversation history to inform later referring expressions. 
Studying how children play iterated reference games can provide insight into the developmental trajectory of the ability to produce referential expressions in order to achieve joint understanding. 

One influential early study suggested that 4-5-year-old preschoolers struggle with child-child referential communication [@glucksberg1966]. In their paradigm, one child was given a set of 6 blocks in a specific order. Their task was to describe the image on each block so their partner could pick out their corresponding block. As children described and selected blocks, they stacked them on pegs. While 4-5-year-old children succeeded on practice trials with familiar shapes and visual access to each other's blocks, children failed on critical trials where the blocks had abstract drawings and there was no visual access. Even after multiple rounds with the same images, children were not able to correctly order the blocks. @glucksberg1966 attributed children's communicative failures to their production of ego-centric descriptions that did not account for the other child's perspective.  

## Re-evaluating children's failures in referential tasks 
After this initial experiment, similar studies with older children indicated a gradual improvement through adolescence both for initial accuracy and for the increase in accuracy across repetitions. Still, even the 9th grade sample was noticeably worse than the adult college student sample [@glucksberg1967; @krauss1969]. Given that even teenagers had difficulties with the task, the complex stacking paradigm and the large number of potential targets may have posed task demands that prevented accurate measurement of children's abilities. 

```{r interface, fig.env = "figure", fig.pos = "t!", out.width="\\textwidth", fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Experimental setup and procedure. Panel A shows the experimental setup. Panel B shows the procedures for each experiment;  within critical blocks targets were ordered randomly.\\label{game}", cache=FALSE}

knitr::include_graphics("diagram.pdf")


# edit diagram at 
# https://docs.google.com/drawings/d/1kLfIGdPGeEAQgXG--FE7eyLKzX0DjTZxwfQOIhvW19I/edit?usp=sharing
```

Though no evidence has directly contradicted @glucksberg1966, a number of studies have revealed early emerging skills in the preschool years that support referential communication. Preschool-aged children are faster to select a target when it is referred to in a consistent way [@graham2013; @matthews2010]. When a change in visual context renders previous descriptions overinformative, 6-year-olds (but not 4-year-olds) are more likely to use consistent referential expressions when they keep talking to the same partner, but switch to simpler terms with a new partner [@koymen2014]. These studies suggest that young children are sensitive to the norm of consistent descriptions in cooperative communication. 

Further, preschool-aged children adapt the informativeness of their referential expressions based on the visual content available to their interlocutor [@matthews2006;@nadig2002;@nilsen2009]. By age 5, children integrate information about other's perspectives into their comprehension of utterances [@sanjuan2015]. 4-5 year old children are faster to rule out competitors and select the correct target when they have learned that their partner is not aware of the competitor object. Children's ability to take partner's perspectives and knowledge states into account is evolving over the preschool years, but overall, by late preschool, children can reason about others’ perspectives to communicate more effectively. 


Still, 4-5-year-old children's referential abilities are far from mature. While children are sensitive to others’ perspectives, they still struggle to appropriately tailor the specificity of their utterances to the visual context, often resulting in under-informative utterances [@matthews2012; @leung2024].  When children must describe one of two very similar images, 4 and 5-year-olds sometimes neglect to mention the relevant features, although they do better when playing in an interactive game than when not [@grigoroglou2019]. By 5 years old, children are sensitive to over- and under-informative utterances, asking for clarification on some under-informative utterances and taking longer to make selections on over-informative utterances [@morisseau2013]. 

A common thread among many developmental studies is that children perform better when the cognitive load of the task is reduced, i.e. when there are fewer possible referents [@abbot-smith2015; @sanjuan2015].  These findings paired with evidence of emerging communicative skills in young children suggest that tailored referential expression production is possible in children, but it is likely to be masked when the task demands are too high. 

Since @glucksberg1966, few studies have revisited the question of whether children can successfully communicate in an iterated reference game. In one study, 8-10-year-olds exhibited adult-like patterns of increasing accuracy, increasing speed, and shorter descriptions across repetitions, but children’s accuracy was still far below adult performance and highly variable between dyads [@branigan2016]. In an iterated reference game where 4- and 6- year-olds communicated to each other via gestures, children were successful at communicating a repertoire of 5 image options with each other [@bohn2019a]. Children's comprehension increased over repetitions, and when children switched roles, they often re-used their partner's gestures. The 6-year-olds showed greater within-dyad similarity in gestures than the 4-year-olds, indicating that children's abilities to form conventional pacts is increasing in this age range. 

Another piece of evidence about children's communicative abilities comes from an iterated reference game where 4-8-year-old children used natural language to communicate with their parents [@leung2024]. In this simple, child-friendly tablet-based task, even 4-year-olds had an initial accuracy above 80% on two-way choice, which rose to above 90% in later repetitions [@leung2024]. Together, the recent work on both iterated and non-iterated reference games with young children provides evidence of young children’s ability to communicate with each other and with adults under the right conditions. Still, the preschool years are a time of rapid development for children as a number of communicative skills are improving between the ages of 3 and 6 years old. 

## The Current Study 

Given the task demands in @glucksberg1966 and work showing that children can succeed in a less demanding paradigm, here we revisit the question of child-child referential communication. In the present study, we re-examine young children's ability to establish effective referring expressions with each other in an iterated reference game using a simplified tablet-based paradigm. Across three studies including a total of `r pairs` pairs of 4-5-year-old preschool children, we found that preschool-aged children were successful in an iterated reference game, suggesting that children's capacity to construct effective referring expressions in novel contexts emerges earlier than previously claimed.


# Experiment 1 

## Methods

Our goal for Experiment 1 was to test young children's ability to coordinate to produce descriptions of abstract shapes that their partner could understand. Young children can be very sensitive to task demands and cognitive load [@turan-kucuk2024; @keen2003; @carruthers2013], so we adapted the experimental framework from @leung2024, and further simplified it by reducing the total pool of targets and the number of trials. This experiment was pre-registered at \url{osf.io/kcv8j}. 

### Participants

4 and 5-year-old children were recruited from a university preschool during the school day. Children played with another child from the same class. Experiment 1 was conducted between June and August 2023. Pairs of children were included in analyses if they completed at least 8 of the 12 critical trials. We had 19 games that completed 12 critical trials, and 1 game that completed 11 critical trials. Of the 40 children, 21 were girls, and the median age was 4;9, with a range of 4;0 to 5;10. An additional 8 games were excluded for being pilot runs or not completing enough trials. 

### Materials
For the target stimuli, we used four of the ten tangram images from @leung2024, chosen based on visual dissimilarity (Figure \ref{game}B). We coded the matching game using Empirica [@almaatouq2021], hosted it on a server, and then accessed the game on tablets that were locked in a kiosk mode so children could not navigate away from the game.

### Procedure
Once a pair of children agreed to play the game, a research assistant took them to a quiet testing room. Children were introduced to a stuffed animal "Smurfy" who wanted to play a matching game. Children sat across a table from each other, each with a tablet in front of them (Figure \ref{game}A). On each trial, one child was the "teller" and saw a black box around one of two images on their screen and was asked to "tell Smurfy what they see" in the black box. The "guesser" saw the same two images in a randomized order and tried to select the described image to help Smurfy make a match. When the guesser selected an image, both children received feedback in form of a smiley or frowny face and an excited or disappointed sound. After each trial, children switched roles. Children passed Smurfy back and forth to keep track of whether they were the "guesser" or "teller" on a given trial.

Children completed two warm-up trials with black and white images of familiar shapes, followed by 3 blocks of the 4 target images (Figure \ref{game}B). Targets were randomly paired with another of the critical images as the foil. 

The experimenters running the game did not volunteer descriptions, but they did scaffold the interaction, prompting children to describe the images, and sometimes repeating children's statements (especially when utterances were inaudible or the child did not respond immediately; this aspect of the procedure was modified in Experiment 2 and 3). The entire interaction was video-recorded. 

### Data processing

Children's selections and the time to selection were recorded from the experiment software. Children's descriptions were automatically transcribed from the video using Whisper [@radford2022] for the first pass and then hand-corrected by experimenters. Transcripts were hand-annotated for when each trial started, who said each line, and what referential descriptions were used. 
We excluded trials where the "teller" did not produce a description, where all description was unintelligible and impossible to transcribe, or where the "guesser" did not make a selection. After exclusions, we had `r joint_data |> filter(expt=="1") |> nrow()` trials remaining. 

Statistical analyses were run in brms [@burkner2018] with weakly informative priors. We report estimates and 95% credible intervals. The experimental set-up, analysis code, de-identified transcripts, and performance data for all experiments is available at \url{osf.io/7d3ne}.


## Results
### Accuracy and speed

```{r fig-accuracy, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="80%", fig.width=6, fig.height=3, fig.cap = "Children's accuracy at selecting the correct target over time. Error bars are bootstrapped 95% CIs with a linear trend line overlaid. \\label{acc}" }
joint_data |>
  ggplot(aes(x = trial+1, y = correct)) +
    geom_smooth(method = "lm", color = "black") +
  stat_summary(aes(color = type), fun.data = "mean_cl_boot") +
  #stat_summary(fun.data = "mean_cl_boot", geom = "linerange", color = "black") +
  scale_color_manual(values = time_palette) +
  # geom_bar(position = position_dodge(.9), color = "black", fill = "#19ADDE", width = .7) +
  # geom_text(aes(label = percent), hjust = 1.6, color = "white", size = 3) +
  labs(color="Block")+
  xlab("Trial") +
  ylab("Accuracy") +
  geom_vline(xintercept = 4.5, lty="dashed")+
    geom_vline(xintercept = 8.5, lty="dashed")+
    geom_vline(xintercept = 12.5, lty="dashed")+
  scale_x_continuous(breaks = seq(1, 16, 1), expand = c(0.02, 0.02)) +
  scale_y_continuous(breaks = seq(0, 1, .2), expand = c(0, 0.04)) +
  coord_cartesian(ylim = c(0.3,1))+
  geom_hline(yintercept = .5) +
  facet_grid(str_c("Expt ",expt) ~ .) +
  theme(
    panel.grid = element_blank(),
    strip.background = element_blank()
  )
```

```{r}
acc_mod_1 <- read_rds(here(mod_results, "acc_1.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))

acc_form <- read_rds(here(mod_form, "acc_1.rds"))
```

Our primary question was whether children could accurately communicate the intended target, as prior work is often interpreted as indicating the children at kindergarten age cannot communicate about abstract shapes successfully [@glucksberg1966]. To test for changes in accuracy over time, we fit a Bayesian mixed effects logistic regression predicting accuracy.^[`r acc_form |> form()` In this and other models, we deviate from the pre-registration by adding random by-image slopes to better match the experimental design.] Children's accuracy was above chance (Odds Ratio: `r stats_text(acc_mod_1,1)`) with a possible increase in accuracy over the game (OR of one trial later: `r stats_text(acc_mod_1, 2)`, Figure \ref{acc}). This level of accuracy is generally in-line with accuracies from 4-year-olds playing with their parents in @leung2024 and indicates that children can understand and succeed at the task. 



```{r}
speed_mod_1 <- read_rds(here(mod_results, "speed_1.rds"))

speed_form <- read_rds(here(mod_form, "speed_1.rds"))
```

As another measure of children's performance, we looked at how long children spent on each trial. We ran a Bayesian mixed effects linear regression predicting the time to selection in seconds.^[`r speed_form |> form()`] The first critical trial averaged `r stats_text(speed_mod_1, 1)` seconds, and children tended to speed up over time, albeit with wide variability (`r stats_text(speed_mod_1, 2)` seconds / trial). Children were able to achieve the same accuracy in less time, suggesting that they were becoming more efficient at completing the task. 

### Description length

```{r description, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="80%", fig.width=6, fig.height=3, fig.cap = "Length of description produced by the teller each trial, shown on a log scale. Grey dots are individual data points, colored dots are per trial means with bootstrapped 95% CIs. \\label{length}" }
joint_data |> 
  ggplot(aes(x = trial+1, y = words, color = type)) +
  geom_jitter(alpha = .5, color = "grey") +
  stat_summary(fun.data = "mean_cl_boot") +
  scale_x_continuous(breaks = seq(1, 20, 1), expand = c(0, 0)) +
    geom_vline(xintercept = 4.5, lty="dashed")+
    geom_vline(xintercept = 8.5, lty="dashed")+
    geom_vline(xintercept = 12.5, lty="dashed")+
  scale_color_manual(values = time_palette) +
  geom_smooth(method = "lm", color = "black") +
  scale_y_log10()+
  xlab("Trial") +
  ylab("Words") +
  labs(color="Block")+
  facet_grid(str_c("Expt ",expt) ~ .) +
  theme(
    legend.position = "right",
    panel.grid = element_blank(),
    strip.background = element_blank()
  )
```




```{r}
description_mod_1 <- read_rds(here(mod_results, "description_1.rds"))

description_form <- read_rds(here(mod_form, "description_1.rds"))

description_robustness_mod_1 <- read_rds(here(mod_results, "all_description_1.rds"))
```

In iterated reference games with adults, description lengths usually shorten over repeated references [@clark1986; @hawkins2020dynamics; @boyce2024]. We were curious if children's descriptions would display the same trend, so we ran a Bayesian mixed effects linear regression predicting the number of words in the description the "teller" produced.^[`r description_form |> form()`] On the first critical trial, descriptions averaged `r stats_text(description_mod_1, 1)` words, and description length was relatively stable over time (change of `r stats_text(description_mod_1, 2)` words per trial, Figure \ref{length}). Thus, children's increasing speed was not from shorter utterances, but instead from some combination of improved task understanding, faster utterance planning, and faster decisions of what to select.

<!-- this description metric is just the length of the description, taking out repetition/rephrasing from the child. We could also include the robustness check which is the length of all the (on-topic) teller-guesser interaction (including repeating/rephrasing, questions, I don't knows, etc), which is also very flat. -->

Some examples to illustrate the variety of effective descriptions children employed are shown in Table \ref{example}. 

### Convergence 

```{r sims, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="80%", fig.width=6, fig.height=3, fig.cap = "Semantic similarity between pairs of descriptions from different sources. Dots are means and lines are bootstrapped 95% CIs.  \\label{sim}" }



joint_similarities|>
  mutate(source = case_when(
    speaker1 == speaker2 ~ "same teller",
    game1 == game2 ~ "same game",
    T ~ "different games")) |> 
  left_join(labels) |> 
  ggplot(aes(x = source, y = sim, color = img_source)) +
      stat_summary(aes(group=img_source),fun.data = "mean_cl_boot", position = position_dodge(width = .3), geom="line") +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .3)) +
  labs(y = "Cosine similarity", x = "Comparing two utterances from ...", color = "Target") +
  facet_grid(str_c("Expt ",expt) ~ .) +
  scale_color_brewer(palette="Dark2") +
  theme(
    legend.position = "right",
    legend.text = element_markdown(color = "black", size = 11),
    panel.grid = element_blank(),
    strip.background = element_blank()
  )
```


```{r}
sim_across_between_1_results <- read_rds(here(mod_results, "sim_across_between_1.rds"))

sim_across_between_form <- read_rds(here(mod_form, "sim_across_between_1.rds"))
```

While description length is often used as a proxy for measuring convention formation, it does not capture semantic overlap between utterances. @boyce2024 introduced a more sensitive measure of semantic convergence that compares the content of utterances using word embeddings to trace how similarities within and across games change over time. To measure convergence of utterances, they compared how the similarities between utterances from a given block and the final block (conventionalized) utterances increased over the course of the game. With only 3 blocks of descriptions, we do not expect semantic similarity for descriptions of a given target to show any meaningful change over time. However, we can test for a more coarse measure of sensitivity to partner: whether children's utterances are more like the utterances of their partner than like utterances from children in other games. If children are fully ego-centric [as suggested by @glucksberg1966], their choices of descriptions would be independent from their partners, and equally similar (or dissimilar) to descriptions from their partner and from other peers.  

Following the methods of @boyce2024, we embedded each description in a semantic vector space using S-BERT [@reimers2019], and then used the cosine between embeddings as a measure of semantic similarity. 

We compared the semantic similarities between descriptions of the same target based on who produced the description (Figure \ref{sim}).  We used a Bayesian mixed effects linear regression to predict similarity.^[`r sim_across_between_form |> form()`] Utterances were more similar if they came from the same partnership (`r sim_across_between_1_results |> stats_text(2,3)`). Utterances were slightly more similar still if they came from the same person (`r sim_across_between_1_results |> stats_text(3,3)`), which is expected since children are likely to be fairly consistent with themselves. However, children used descriptions that were much more similar to their partner's than to other children's (Figure \ref{sim}), indicating sensitivity to their partner's expressions. 

## Discussion

In Experiment 1, we adapted the paradigm of @leung2024 for pairs of children, taking an already simple set-up and making it shorter. Our goal was to see if young children were at all able to provide adequate descriptions, so children received a lot of scaffolding around the experimental interaction. In this supportive environment, children provided short descriptions that allowed their partner to select the correct target most of the time. 
The scaffolding provided by experimenters sometimes included echoing children's descriptions, which could potentially influence children's responses. In Experiment 2, we repeated the same paradigm, with a tighter experimental script and a larger sample size. 


```{=latex}

\begin{table}
	\caption{Example descriptions children successfully used to identify different target images in Experiments 2 and 3.
}
	\label{example}
	\begin{tabular}[t]{p{14em}p{3em}}
		\hline
		%hold
	
		$\bullet$ vampire & \multirow{4}{*}{\includegraphics[width=.5in]{E1.jpg}}\\
		$\bullet$ a person flying &\\
		$\bullet$ a person &\\
		$\bullet$ a kite &\\
		\multicolumn{2}{l}{$\bullet$ a triangle with a head on it with feet}\\
				\multicolumn{2}{p{17em}}{$\bullet$  somebody skydiving, not in the airplane}\\
		\hline
		$\bullet$ airplane & \multirow{4}{*}{\includegraphics[width=.5in]{D1.jpg}}\\
		$\bullet$ alligator &\\
		$\bullet$ a person fell down &\\
		$\bullet$ a boat &\\
		\multicolumn{2}{p{17em}}{$\bullet$ a person that's in a race car that has one triangle and two triangles}\\
		\hline
			$\bullet$ person & 		\multirow{4}{*}{\includegraphics[width=.5in]{I1.jpg}}\\
		$\bullet$ a person holding a sandwich &\\
		$\bullet$ a people carrying a box of dirt &\\
		$\bullet$ a monster &\\
		\multicolumn{2}{p{17em}}{$\bullet$ someone holding a plate and giving it to a restaurant and has watermelon}\\
		\hline
		$\bullet$ person & \multirow{3}{*}{\includegraphics[width=.5in]{B1.jpg}}\\
		$\bullet$ a person walking &\\
		$\bullet$ a person looking down &\\
		\multicolumn{2}{p{17em}}{$\bullet$ a people, but it doesn't have any arms} \\
		\hline
	\end{tabular}
	\quad
	\begin{tabular}[t]{p{14em}p{3em}}
		\hline
		$\bullet$ a people & 		\multirow{4}{*}{\includegraphics[width=.5in]{tangram_A.png}}\\
	$\bullet$ a horse & \\
	$\bullet$ stomping & 	\\
		\multicolumn{2}{p{17em}}{$\bullet$ a person that’s walking and has a square, like on his shoulder}\\
	\multicolumn{2}{p{17em}}{$\bullet$ a diamond on the back, this leg is one leg on the ground, one leg up in the air}\\
		\hline
		$\bullet$ a bunny & \multirow{4}{*}{\includegraphics[width=.5in]{tangram_E.png}}\\
$\bullet$ a kangaroo &\\
$\bullet$ a mountain with some triangles &\\
$\bullet$ two triangles on the top &\\
\multicolumn{2}{p{17em}}{$\bullet$ a person looking backwards with a dress and a bow}\\
		\hline
		$\bullet$ a shoe &  \multirow{3}{*}{\includegraphics[width=.5in]{tangram_G.png}}\\
		$\bullet$  a walrus &\\
$\bullet$ something looking down &\\
\multicolumn{2}{p{17em}}{$\bullet$ a pterodactyl with a flag on its back }\\

\multicolumn{2}{p{17em}}{$\bullet$  a diamond on the top, and a triangle on the bottom}\\
		\hline
		$\bullet$ a bottle & \multirow{4}{*}{\includegraphics[width=.5in]{tangram_H.png}}\\
		$\bullet$ a diamond on the top &\\
 $\bullet$ a weird looking banana &\\
$\bullet$ candy &\\

		\hline
	\end{tabular}
\end{table}

```


# Experiment 2 

## Methods

As Experiment 2 was very similar to Experiment 1, we focus on the differences from Experiment 1. Experiment 2 was pre-registered at \url{osf.io/y2dax}. 

The biggest change between the experiments was increasing the number of repetitions of target stimuli from 3 to 4 (from 12 to 16 trials). The greater number of trials in Experiment 2 made it possible to look for changes over time that could be indicative of convergence to shared descriptions within a game and divergence between games. 

### Participants
Experiment 2 was run between March and August of 2024, at the same preschool as Experiment 1. We did not intend to resample children who had already participated in experiment 2; however, after the end of data collection, we noticed that 5 children included in experiment 2 had previously been part of experiment 1.^[One experiment 2 game had two children who had been in experiment 1 pilots, two games each had one child previously included in experiment 1, and one game had a child who had started an experiment 1 game that was excluded for too few trials.] 30 pairs of children completed all 16 critical trials, and 1 pair of children completed 10 critical trials. Our target age range was 4 and 5-year-olds, but one older 3-year-old was unintentionally included. Of the 62 children, 30 were girls, and the children had a median age of 4;8, and a range of 3;9-5;9. An additional 6 games were excluded for being pilot runs or not completing enough trials.  

### Materials
The same 4 critical images were used as in Experiment 1. In response to some children struggling with the abrupt switch from familiar to non-nameable shapes, we introduced more practice trials for Experiment 2. We used a total of 4 practice trials to provide a gradient from familiar shapes to less recognizable, blockier shapes (Figure \ref{game}B). 

### Procedure
The procedure was much the same as Experiment 1(Figure \ref{game}B). We added an initial "bubble popping" exercise to give children practice tapping the tablet appropriately (this was an issue for some children in Experiment 1). The experimental script was fully written out and memorized by experimenters so children all received the same instructions. We wrote up contingency statements that the experimenter could use to prompt children who were not giving descriptions or making selections. Experimenters helped with game mechanics such as whose turn it was to tell and who should press the screen, but avoided contributing or repeating any content about the images or the descriptions. 

### Data processing
Data were processed in the same way as Experiment 1. After excluding trials where children did not give a description or where the experimenter echoed a child's description, we had `r joint_data |> filter(expt=="2") |> nrow()` trials total. 

## Results
### Accuracy and speed

```{r}
acc_mod_2 <- read_rds(here(mod_results, "acc_2.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))
```


```{r}
speed_mod_2 <- read_rds(here(mod_results, "speed_2.rds"))
```

In Experiment 2, children's accuracy was above chance (Odds Ratio: `r stats_text(acc_mod_2,1)`) and relatively stable over time (OR of one trial later: `r stats_text(acc_mod_2, 2)`, Figure \ref{acc}). 
The first critical trial averaged `r stats_text(speed_mod_2, 1)` seconds, and children's speed increased over repetitions, with wide uncertainty (`r stats_text(speed_mod_2, 2)` seconds / trial). <!--Children were initially faster in Experiment 2 than Experiment 1, possibly due to the increased number of practice trials and pre-training on how to press the screens. -->Taken together, we find more evidence that children can successfully communicate with each other about these abstract shapes, and do so with increasing efficiency. 

### Description length


```{r}
description_mod_2 <- read_rds(here(mod_results, "description_2.rds"))

description_robustness_mod_2 <- read_rds(here(mod_results, "all_description_2.rds"))

```


The average length of descriptions on the first trial was `r stats_text(description_mod_2, 1)` words and description length was relatively stable over time (change of `r stats_text(description_mod_2, 2)` words / trial, Figure \ref{length}). This finding is comparable to Experiment 1, again finding that children produce short utterances without much change in length over time.

### Convergence 


```{r}
sim_across_between_2_results <- read_rds(here(mod_results, "sim_across_between_2.rds"))

sim_across_between_form <- read_rds(here(mod_form, "sim_across_between_2.rds"))

sim_across_2_results <- read_rds(here(mod_results, "sim_across_2.rds"))

sim_across_form <- read_rds(here(mod_form, "sim_across_2.rds"))

sim_to_next_2_results <- read_rds(here(mod_results, "sim_to_next_2.rds"))

sim_to_next_form <- read_rds(here(mod_form, "sim_to_next_2.rds"))

sim_to_last_2_results <- read_rds(here(mod_results, "sim_to_last_2.rds"))

sim_to_last_form <- read_rds(here(mod_form, "sim_to_last_2.rds"))
```

As a coarse measure of partner-sensitivity, we repeated the semantic analysis from Experiment 1. Utterances were more similar if they came from the same partnership (`r sim_across_between_2_results |> stats_text(2,3)`) and were slightly more similar if they came from the same person (`r sim_across_between_2_results |> stats_text(3,3)`). 

As Experiment 2 had 4 blocks, we examined whether descriptions were converging semantically toward the final description. We compared the utterances from the first three blocks to the descriptions in the last block using a Bayesian mixed effects linear regression predicting similarity.^[`r sim_to_last_form |> form()`] Over the first three blocks, descriptions became increasingly similar to the last block description (`r sim_to_last_2_results |> stats_text(2,3)`). Descriptions from the same child would be expected to be more similar than descriptions from the partner as a sign of internal consistency; descriptions from the same child were only marginally more similar, with wide uncertainty (`r sim_to_last_2_results |> stats_text(3,3)`). Although over time descriptions did get more similar to the last block utterance, the semantic distance between adjacent block utterances did not clearly increase over repetition (`r sim_to_next_2_results |> stats_text(2,3)`). 

Partnerships may also diverge from one another as groups focus on distinct aspects of the image. We tested whether descriptions in different games diverged over time using a Bayesian mixed effects linear regression.^[`r sim_across_form |> form()`] As the games progressed, descriptions to the same target from different games did not change substantially in similarity (`r sim_across_2_results |> stats_text(2,3)`). 

```{r sim2, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="100%", fig.width=7, fig.height=3, fig.cap = "Semantic similarity between descriptions from earlier blocks (1-3) and the last block in Experiments 2 and 3.  Heavy dots are means with bootstrapped 95% CIs. \\label{tolast}" }
joint_similarities |> 
  filter(game1==game2) |> 
  filter(later==3) |> 
  mutate(same_speaker = ifelse(speaker1 == speaker2, "Same teller", "Different teller")) |>left_join(labels) |> 
  ggplot(aes(earlier+1, sim, color = img_source)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2), geom="line") +
    geom_smooth(color="black", method="lm")+
  facet_grid(str_c("Expt ", expt)~same_speaker) +
  scale_x_continuous(breaks=c(1,2,3), labels=c("1", "2", "3"))+
  labs(x = "Comparing an earlier block (1-3) to last block (4)", y = "Cosine Similarity", color = "Target") +
scale_color_brewer(palette="Dark2") +
  theme(
    legend.position = "right",
    legend.text = element_markdown(color = "black", size = 11),
    panel.grid = element_blank(),
    strip.background = element_blank()
  )


```

## Discussion

In Experiment 2, we repeated the matching game from Experiment 1 with a tighter experimental script, a larger sample size, and more trials per game. We again found that children produced short descriptions that enabled their partners' to identify the target most of the time. Children's descriptions showed semantic convergence toward shared conventions for referring to each target within games. 

# Experiment 3

The first two experiments demonstrated children's ability to communicate referentially, but were limited in their generality by the use of a specific set of 4 fairly humanoid tangram figures. To explore the generality of the results to a different set of potentially harder tangram stimuli, we conducted Experiment 3. 

## Methods
As Experiment 3 was very similar to Experiment 2, we focus on the differences from Experiment 2. Experiment 3 was pre-registered at \url{osf.io/tk7sc}. 

The procedure for Experiment 3 matched Experiment 2, and the only change was in the stimuli used.


### Participants
Experiment 3 was run between December 2024 and January 2026, at the same preschool as Experiments 1 and 2. Because the stimuli changed, we allowed children who had participated in a prior experiment to participate again. 6 children included in experiment 3 had previously been part of experiment 2 (4 of whom were included in experiment 2 data, 2 of whom had been in experiment 2 pilots). 30 pairs of children completed all 16 critical trials, and 1 other pair completed 11 trials. Of the 62 children, 33 were girls, and the children had a median age of 4;9, and a range of 4;0-5;10. An additional 17 games were excluded for being pilot runs, including repeat participants, not completing enough trials, or including a 3-year-old participant.  



### Materials
A different set of critical images were used (see Figure \ref{game}B). These were chosen from a set of commonly used tangram images [@clark1986;@hawkins2020dynamics;@boyce2024], to be fairly distinct from each other. We also switched the stimuli for the 3rd and 4th practice trials to be more abstract, so children would not be surprised by the critical stimuli not having established, canonical names. 

### Procedure
The procedure was the same as for Experiment 2. <!--The bubble popping practice was modified so that both rounds of bubbles were colored dots, because children in Experiment 2 sometimes did not identify the smiley faces as more bubbles to pop. -->

### Data processing
Data were processed in the same way as Experiment 1. After excluding trials where children did not give a description or where the experimenter echoed a child's description, we had `r joint_data |> filter(expt=="3") |> nrow()` trials total. 

## Results
### Accuracy and speed

```{r}
acc_mod_3 <- read_rds(here(mod_results, "acc_3.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))

acc_pct<- joint_data |> group_by(expt) |> summarize(acc=mean(correct, na.rm=T)*100)
```


```{r}
speed_mod_3 <- read_rds(here(mod_results, "speed_3.rds"))
```

In Experiment 3, children's initial accuracy was slightly above chance, but with wide uncertainty (Odds Ratio: `r stats_text(acc_mod_3,1)`).  Children's accuracy tended to increase slightly over time, again with some uncertainty (OR of one trial later: `r stats_text(acc_mod_3, 2)`, Figure \ref{acc}). Children's overall accuracy was lower in Experiment 3 (`r round(acc_pct |> pluck(2,3))`%) than in the prior experiments (`r round(acc_pct |> pluck(2,2))`%), potentially indicating that the stimuli were more difficult. 

The first critical trial averaged `r stats_text(speed_mod_3, 1)` seconds, and children got faster over time (`r stats_text(speed_mod_3, 2)` seconds / trial). Overall, we find evidence that children's ability to communicate with increasing efficiency generalizes to different abstract images.  

### Description length


```{r}
description_mod_3 <- read_rds(here(mod_results, "description_3.rds"))

description_robustness_mod_3 <- read_rds(here(mod_results, "all_description_3.rds"))

description_mean <- joint_data |> group_by(expt) |> summarize(length=mean(words, na.rm=T))
```


The average length of descriptions on the first trial was `r stats_text(description_mod_3, 1)` words and description length was relatively stable over time (change of `r stats_text(description_mod_3, 2)` words / trial, Figure \ref{length}). Descriptions in experiment 3 averaged 7 words, compared to an average of 3-4 words in the prior experiments. Again, the difference may be due to the increased difficulty of the stimuli. 

### Convergence 

```{r}
sim_across_between_3_results <- read_rds(here(mod_results, "sim_across_between_3.rds"))


sim_across_3_results <- read_rds(here(mod_results, "sim_across_3.rds"))

sim_to_next_3_results <- read_rds(here(mod_results, "sim_to_next_3.rds"))

sim_to_last_3_results <- read_rds(here(mod_results, "sim_to_last_3.rds"))

```

We repeated the semantic analyses from Experiment 2. We again found that utterances were more similar if they came from the same partnership (`r sim_across_between_3_results |> stats_text(2,3)`) and if they came from the same person (`r sim_across_between_3_results |> stats_text(3,3)`). 

Over the first three blocks, descriptions became increasingly similar to the last block description (`r sim_to_last_3_results |> stats_text(2,3)`). Descriptions from the same partner were slighly more similar to each other, with some uncertainty (`r sim_to_last_3_results |> stats_text(3,3)`) Over time, the semantic similarity between adjacent block utterances increased (`r sim_to_next_2_results |> stats_text(2,3)`). 

Unlike the patterns found with adults, we found that the similarity between utterances in different games was relatively stable over time (`r sim_across_3_results |> stats_text(2,3)`). While children show some of the same patterns as adults on these stimuli, such as sensitivity to their partners descriptions, and some convergence towards conventions, there was not increasing group-specificity of descriptions over time. 

## Discussion

In Experiment 3, we tested whether preschool children's ability to coordinate on mutually understandable labels to identify targets in a repeated matching game would generalize to a different, and perhaps harder, set of abstract stimuli. In line with the prior experiments, children used relatively short descriptions, picked the correct targets most of the time, and showed signs of converging with their partner on names for each image. Possibly because the images were more difficult, children used longer descriptions and had lower accuracy than in the first two experiments. 

# Pooled analysis

We conducted an exploratory analysis over the pooled dataset first in order to understand the consistency of specific results across experiments and secondly to explore potential moderators of children behavior across the larger dataset. 

## Consistency of results

```{r}
acc_mod_meta <- read_rds(here(mod_results, "acc_meta.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))

speed_mod_meta <- read_rds(here(mod_results, "speed_meta.rds"))
description_mod_meta <- read_rds(here(mod_results, "description_meta.rds"))

description_robustness_mod_meta <- read_rds(here(mod_results, "all_description_meta.rds"))

sim_across_between_mod_meta <- read_rds(here(mod_results, "sim_across_between_meta.rds"))


sim_to_last_mod_meta <- read_rds(here(mod_results, "sim_to_last_meta.rds"))

sim_to_next_mod_meta <- read_rds(here(mod_results, "sim_to_next_meta.rds"))

sim_across_mod_meta <- read_rds(here(mod_results, "sim_across_meta.rds"))
```

Because of variability between pairs of children and between different target images, there is variability in our numerical estimates of results across different experiments. 
In order to maximize power and obtain overall estimates of effects, we re-ran the statistical models, pooling across the experiments. In addition to random slopes and intercepts for each pair and each image, we add random slopes and intercepts by experiment as well.

### Accuracy and speed 
Pooling across the three experiments, children's accuracy was above chance at the start of the game (OR: `r stats_text(acc_mod_meta,1)`), but it is unclear whether children's accuracy increased over the course of the game (OR of one trial later: `r stats_text(acc_mod_meta, 2)`). Across all the experiments, it is unclear whether children sped up over the course of the game (effect of one trial later: `r stats_text(speed_mod_meta, 2)` seconds).

### Description length
Descriptions produced by tellers averaged `r stats_text(description_mod_meta, 1)` words on the first trial, and description length was relatively stable over time (change of `r stats_text(description_mod_meta, 2)` words per trial).


### Convergence
Utterances were more similar if they came from the same partnership (increase in cosine similarity: `r sim_across_between_mod_meta |> stats_text(2,3)`) and were more similar still if they came from the same person within the partnership (`r sim_across_between_mod_meta |> stats_text(3,3)`).

For the other semantic analyses, we pooled across experiments 2 and 3 which had 4 blocks. In the combined model, we found that the similarity the last block utterance increased across blocks (`r stats_text(sim_to_last_mod_meta, 2,3)`) and was marginally higher, albeit with some uncertainty, when the same child produced both utterances (`r stats_text(sim_to_last_mod_meta, 3,3)`). In a combined model, similarity to the next block utterance also increased across blocks (`r stats_text(sim_to_next_mod_meta, 2,3)`) and was higher when the same child produced both utterances (`r stats_text(sim_to_next_mod_meta, 3,3)`). Across the two experiments, the similarity of utterances from different pairs to the same stimulus remained fairly stable across blocks (`r stats_text(sim_across_mod_meta, 2,3)`). 

Different pairs of children used different descriptions for the target images, and within a partnership, children's descriptions show convergence toward a shared concept. However, this convergence was not coupled with increasing dissimilarity to the descriptions of other pairs. The overall pattern of results is a partial match for the patterns reported in reference games between adults [@boyce2024]. 


## Sensitivity to prior communicative success

One aspect of mature cooperative communication is tailoring descriptions to the knowledge state of the interlocuter. If an interlocutor is confused or misunderstands a description, adults try a different description or add more details to help their interlocuter. In iterated reference games, adults shorten descriptions more when the prior description was successful compared to when it was not [@hawkins2020dynamics].

```{r}
sim_acc_to_next_mod_meta <- read_rds(here(mod_results, "sim_acc_to_next_meta.rds"))
sim_acc_to_next_form <- read_rds(here(mod_form, "sim_acc_to_next_meta.rds"))

```

If children are sensitive to their partner's perspective, then whether a description was successful should influence whether the same description, or a variant, will be used in future rounds.  To test whether accuracy is predictive of similarity to future descriptions, we ran a post-hoc Bayesian linear model predicting similarity to the next block description in terms of accuracy.^[`r form(sim_acc_to_next_form)`] Descriptions that elicited a correct response were more similar to the next block description (`r stats_text(sim_acc_to_next_mod_meta, 2, 3)`) with no substantial interaction with block number or whether both descriptions came from the same teller. This pattern of results is consistent with the expectation that children are more likely to stick to their own description or repeat the other child's description if it was previously successful. 

## Age and gender as moderators of referential success

We consider the effects of participant age and gender as an exploratory measure. Children were not matched with their partner based on age and gender, so different ages (within the 4-5 year old target age range) sometimes played together, and children sometimes played with same-gender and sometimes with different-gender partners. 

```{r age-acc, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="80%", fig.width=6, fig.height=3, fig.cap = "Accuracy of selections across all experiments, graphed by the mean age of child in that game, and colored by the number of girls in the pair. Each dot is a game, and linear fits are overlayed. \\label{ageacc}", eval=F }
joint_data |>
  mutate(mean_age = (listener_age + speaker_age) / 2, girlness = (listener_gender == "female") + (speaker_gender == "female")) |>
  ggplot(aes(x = mean_age, y = correct, color = as.character(girlness))) +
  labs(x="Mean age of participants (months)", y="Accuracy", color="Number of girls")+
  geom_jitter(data=joint_data|>
  mutate(mean_age = (listener_age + speaker_age) / 2, girlness = (listener_gender == "female") + (speaker_gender == "female")) |> group_by(expt, game, mean_age, girlness) |> summarize(correct=mean(correct, na.rm=T))) +
  scale_y_continuous(breaks = seq(0, 1, .2), expand = c(0, 0.04)) +
  coord_cartesian(ylim = c(0.3,1))+
  geom_hline(yintercept = .5) +
  scale_color_manual(values=c("#DC322FFF","#2AA198FF" ,"#268BD2FF"  ))+
  geom_smooth(method = "lm", show.legend=F)
```


```{r}
acc_demog_meta <- read_rds(here(mod_results, "acc_demog.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))

acc_demog_form <- read_rds(here(mod_form, "acc_demog.rds"))

description_demog_meta <- read_rds(here(mod_results, "description_demog.rds"))
description_demog_form <- read_rds(here(mod_form, "description_demog.rds"))
```

### Accuracy 
<!--The effects of children's age and gender on their performance are shown in Figure \ref{ageacc}.--> To test for possible effects of children's age and gender on matcher accuracy, we ran a mixed effects logistic regression, where we considered possible effects of the age of each child (centered at mean age of all the children who participated) and the gender of each child on the accuracy of their selections^[`r form(acc_demog_form)`]. Accuracy was higher for older children (OR for one month older teller: `r stats_text(acc_demog_meta, 3,2)`, OR for one month older guesser: `r stats_text(acc_demog_meta, 2,2)`). Accuracy was also higher when the guesser was a girl (OR: `r stats_text(acc_demog_meta, 4,2)`), but was not credibly higher when the teller was a girl (OR: `r stats_text(acc_demog_meta, 5,2)`). 

### Description length
We also tested whether children's age or gender affected how many words they produced in their descriptions. We ran a mixed effects linear regression, where we considered the ages and genders of both children as possible predictors of description length^[`r form(description_demog_form)`]. Older children tended to produce longer descriptions (effect of one month older `r stats_text(description_demog_meta,3,2)`), but there was no effect of age of guesser (`r stats_text(description_demog_meta, 2,2)`). For gender, there was no effect of teller gender on description length (girls produced `r stats_text(description_demog_meta, 5,2)` words compared to boys), but tellers produced longer descriptions for boy guessers (`r stats_text(description_demog_meta, 4,2)`). There were not substantial effects of trial order or interactions between demographics and trial order. 

## Qualitative observations

Pairs of children varied substantially in what types of descriptions were used, how readily they produced descriptions, and how well they understood and cooperated with the "rules" of the game.

Some children needed reminders from the experimenter about the structure of the game, while others were able to scaffold their own interaction. In one game, the experimenter provided no input after the practice trials because the children rapidly took turns producing referring expressions and selecting the targets. Their advantage could partially be due to being best friends with each other; all children were paired with another child from the same classroom who they were willing to play with, but friendship levels varied. 

Occasionally, a guesser would provide descriptions of the images ("The walking person or the standing person that's holding something?") so the teller just had to indicate which one rather than self-generate a description. 

Some children asked clarifying questions of their partner, but knowing how much information to provide was not always consistent. In one game, child A described the figure as "A human", prompting child B to note "There's two humans." Later in the game, child B used the description "A human", leading child A to ask "Which one?", which child B clarified with "The one that is walking". This anecdote illustrates how emerging abilities can be inconsistent -- finding a description inadequate as a guesser does not always translate into providing a more informative description as a teller.

Other pairs of children relied on the experimenter to say whose turn it was or prompt them with options to make a guess or ask questions, and some children struggled to formulate useful questions (asking their partner just "what do you see?"). Even for children who struggled, their behaviors such as gesturing, trying to turn their iPads to show their partner, or asking the researcher for help, are indicative of attempts to solve the communication problem (albeit in ways that did not follow the "rules" of the game). 

In instances where children did not communicate successfully, it is difficult to know what the limiting factor was. In general, our qualitative impression was that children were more likely to hit limits related to understanding the game structure (such as when tellers tapped their own iPad), cooperating with the game (such as guessers immediately pressing an option before the teller had a chance to say anything), or thinking the task was about correctly "naming" the shape (saying "I don't know what that's called"), than for children to specifically struggle with how to describe an unknown referent adequately.  However, pairs of children also varied significantly in how sensitive they were to collaborating with their partner and adapting descriptions based on their partners descriptions and their prior success. 

# General discussion

Language is a powerful tool for communication, and adult language users can communicate with each other in a partner- and context-sensitive way. Learning to deploy language effectively to achieve communicative goals is part of what children learn when they learn a language, but how well can young children use language to communicate with each other about images without canonical names? Iterated reference games are a rich tradition for studying the emergence of partner- and context- specific referring expressions in adults. In the current work, we presented children with a scaled down version of an iterated reference game to see how their developing linguistic and pragmatic skills would allow them to communicate and coordinate with each other. 

Across 3 experiments and `r pairs` pairs of 4 and 5-year-old children, we tested how well children could produce referential expressions that allowed their partner to find a matching abstract shape. Children varied substantially in what sorts of descriptions they produced, but overall accuracy was high (`r pct`%), indicating that children were generally able to produce adequate descriptions. While this task was substantially scaled down relative to measures used for adult competence, it does suggest that the relevant communication skills are present at least in rudimentary form by the end of the preschool years. 

Unlike adults, children did not display a shortening of referential expressions over the course of the game. It is unclear to what extent the uniformly short descriptions we observed are a product of the simplified task or children's behavioral differences from adults. The low number of options and relatively distinct shapes may have obviated the need for long initial descriptions. Indeed, adult controls in @leung2024 used shorter initial descriptions than adults in studies with larger arrays of harder-to-distinguish images [@hawkins2020dynamics; @boyce2024]. However, young children may also struggle to produce longer descriptions, and young children may be more willing to take guesses when adults would seek additional clarification.

Children did show signs of adapting their utterances to their partner and the conversational context. Children's descriptions became increasingly similar to descriptions in the last block and children's successful utterances were more similar to future utterances, suggesting that children adapted their descriptions and coordinated with their partner towards mutually understandable names for each target.

By reducing the task demands and scaffolding children's interaction with each other, we were able to see that many 4-5 year old children in our sample were able to coordinate with each other on informative utterances in a repeated matching game. In a post-hoc analysis, we also observed that within this age range, older children are somewhat more successful than younger children, although there is wide individual variability. We do not claim that this ability emerges at 4 years old, although we suspect that younger children may struggle more with even these reduced task demands, making it difficult to test child-child coordination in young children. 

Our study was intended as a proof-of-concept test about whether children at this age could coordinate with each other to refer to novel referents. Still, the generalizability of our results is limited by the target population, the target images, and the task structure. We sampled a convenience population of children at a university nursery school. We used two sets of 4 tangram images, which may be easier to distinguish and have higher codability than other target images used in adult iterated reference games. We specifically targeted children's abilities to construct referring expressions that can be jointly understood, so children were provided scaffolding around taking turns and talking to their partner. 

In the broader picture of language acquisition, there is debate over the timing of the emergence of communicative and pragmatic abilities relative to the acquisition of grammar and meaning. On one side, children seem to learn literal semantics far before they display an understanding of some pragmatic implicatures [@huang2009; @noveck2001]; on the other, sensitivity to communicative intent is an early emerging skill that develops in parallel with linguistic knowledge and may bootstrap language learning [@bates1974; @bohn2019a; @tomasello2008]. Our current findings are most consistent with a gradual development of children's communicative and linguistic skills, where the skills emerge early and then are refined over time, as children's cognitive capacities increase. At 4-5 years old, children are already able to establish novel referential conventions with one another as part of their broader ability to communicate and coordinate.


<!--# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.-->

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
