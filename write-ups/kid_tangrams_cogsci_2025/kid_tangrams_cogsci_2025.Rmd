---
title: "TODO Preschoolers form conventional pacts with each other to communicate about novel shapes"
bibliography: preschool-tangrams.bib
csl: apa7.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Veronica Boyce (vboyce@stanford.edu)} \\ Department of Psychology, \\Stanford University \And {\large \bf Bobby Sparks (TODO email) } Department of Psychology, \\Stanford University
    \AND {\large \bf Yannick Mofor (TODO email)} \\ TODO affiliation, Stanford University \And {\large \bf Michael C. Frank (mcfrank@stanford.edu)} \\ Department of Psychology, \\ Stanford University}

abstract: >
  Learning language requires not just learning the facts of a language, but also learning how to use that language to communicate. Iterated reference games require rich communicative skills as participants jointly converge on mutually understandable names for initially novel objects. Some classical experiments with young children are interpreted as showing that 4-5 year old children were incapable of succeeding at iterated references games with each other. More recent work on young children and their parents using simpler paradigms reveal greater abilities even in young children. Here, we revisit the question of young children's referential communicative abilites with iterated reference games played between pairs of 4-5 year old preschoolers. Across 51 pairs of children (TODO double check N), we find that children were Y% accurate, and that they often used descriptions similar to their partner's. Preschoolers' capacity to construct effective referring expressions in novel contexts is consistent with a larger picture of early emerging ability to use language in pragmatic and communicative ways. TODO fix wrap up sentence! TODO possibly shorten!

keywords: >
    development; iterated reference game; TODO keywords
    
output: cogsci2024::cogsci_paper
final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
  fig.width = 3, fig.height = 3, fig.crop = F,
  fig.pos = "tb", fig.path = "figs/",
  echo = F, warning = F, cache = F,
  message = F, sanitize = T
)

library(png)
library(grid)
library(ggplot2)
library(xtable)
library(tidyverse)
library(here)
library(brms)
library(rstan)
library(rstanarm)
library(ggthemes)
library(kableExtra)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())

expt_1 <- "data/expt_1"
expt_2 <- "data/expt_2"
mod_loc <- "code/models"
mod_results <- "code/models/summary"
mod_form <- "code/models/formulae"
time_palette <- c("practice" = "grey", "block 1" = "#E41A1C", "block 2" = "#377EB8", "block 3" = "#4DAF4A", "block 4" = "purple") 

# experiment 1 imports
transcript_1 <- read_csv(here(expt_1, "timed_transcript.csv"))
dat_1 <- read_csv(here(expt_1, "clean_data.csv")) |> rename(trial = trialNum)
exclusion_1 <- transcript_1 %>%
  filter(!is.na(description)) %>%
  filter(role == "S") %>%
  select(game, trial) %>%
  unique() %>%
  mutate("S_talked" = 1)

words_1 <- transcript_1 |>
  filter(!is.na(description)) |>
  mutate(words = description |> str_count("\\S+")) |>
  filter(role == "S") |>
  group_by(game, trial) |>
  summarize(words = sum(words))

clean_1 <- dat_1 %>%
  left_join(exclusion_1) %>%
  filter(S_talked == 1) |>
  left_join(words_1) |>
  mutate(type = case_when(
    trial < 2 ~ "practice",
    trial < 6 ~ "block 1",
    trial < 10 ~ "block 2",
    trial < 14 ~ "block 3"
  ))


sims_1 <- read_rds(here(expt_1, "similarities.rds")) |>
  as_tibble() |>
  inner_join(clean_1 |> select(game1 = game, trial1 = trial, target1 = target, speaker1 = speaker)) |>
  inner_join(clean_1 |> select(game2 = game, trial2 = trial, target2 = target, speaker2 = speaker)) |>
  filter(target1 == target2) |>
  filter(trial1 > 1) |>
  filter(trial2 > 1) |>
  mutate(
    trial1 = trial1 + 2,
    trial2 = trial2 + 2
  ) |>
  mutate(block1 = trial1 %/% 4, block2 = trial2 %/% 4) |>
  mutate(
    same_speaker = (speaker1 == speaker2) |> as.numeric(),
    same_game = (game1 == game2) |> as.numeric(),
    later = ifelse(block1 > block2, block1, block2),
    earlier = ifelse(block1 > block2, block2, block1)
  ) |>
  mutate(target = target1)


# expt 2 imports
transcript_2 <- read_csv(here(expt_2, "transcripts.csv"))
link <- read_csv(here(expt_2, "link_transcripts.csv"))

exclude_2 <- transcript_2 |>
  filter(!is.na(echo)) |>
  select(gameId, trial)

data_2 <- read_csv(here(expt_2, "clean_data.csv")) |>
  rename(trial = trialNum) |>
  anti_join(exclude_2)

transcript_2 <- transcript_2 |>
  anti_join(exclude_2) |>
  filter(!is.na(description))

words_2 <- transcript_2 |>
  mutate(words = description |> str_count("\\S+")) |>
  filter(role == "S") |>
  group_by(gameId, gameConfig, trial) |>
  summarize(words = sum(words))

clean_2 <- data_2 |>
  left_join(words_2) |>
  filter(!is.na(words)) |>
  mutate(type = case_when(
    trial < 4 ~ "practice",
    trial < 8 ~ "block 1",
    trial < 12 ~ "block 2",
    trial < 16 ~ "block 3",
    trial < 20 ~ "block 4"
  )) |>
  filter(!is.na(response)) |>
  mutate(correct = as.numeric(correct))

sims_2 <- read_rds(here(expt_2, "similarities.rds")) |>
  as_tibble() |>
  inner_join(clean_2 |> select(game1 = gameId, trial1 = trial, target1 = target, speaker1 = speaker)) |>
  inner_join(clean_2 |> select(game2 = gameId, trial2 = trial, target2 = target, speaker2 = speaker)) |>
  filter(target1 == target2) |>
  mutate(block1 = trial1 %/% 4, block2 = trial2 %/% 4) |>
  mutate(
    same_speaker = (speaker1 == speaker2) |> as.numeric(),
    same_game = (game1 == game2) |> as.numeric(),
    later = ifelse(block1 > block2, block1, block2),
    earlier = ifelse(block1 > block2, block2, block1)
  ) |>
  mutate(target = target1)
```



```{r, eval=F}
library(tidybayes)

save_summary <- function(model) {
  intervals <- gather_draws(model, `b_.*`, regex = T) %>% mean_qi()

  stats <- gather_draws(model, `b_.*`, regex = T) %>%
    mutate(above_0 = ifelse(.value > 0, 1, 0)) %>%
    group_by(.variable) %>%
    summarize(pct_above_0 = mean(above_0)) %>%
    left_join(intervals, by = ".variable") %>%
    mutate(
      lower = .lower,
      upper = .upper,
      Term = str_sub(.variable, 3, -1),
      Estimate = .value
    ) %>%
    select(Term, Estimate, lower, upper)

  stats
}

do_model <- function(path) {
  model <- read_rds(here(mod_loc, path))
  save_summary(model) |> write_rds(here(mod_loc, "summary", path))
  model$formula |> write_rds(here(mod_loc, "formulae", path))
  print(summary(model))
}


mods <- list.files(path = here(mod_loc), pattern = ".*rds") |> walk(~ do_model(.))
```

```{r}
stats <- function(model, row, decimal = 2) {
  model <- model |>
    mutate(
      Estimate = round(Estimate, digits = decimal),
      Lower = round(lower, digits = decimal),
      Upper = round(upper, digits = decimal),
      `Credible Interval` = str_c("[", Lower, ", ", Upper, "]")
    ) |>
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row, 1], ": ", model[row, 2], " ", model[row, 3])
}

stats_text <- function(model, row, decimal = 2) {
  model <- model |>
    mutate(
      Estimate = round(Estimate, digits = decimal),
      Lower = round(lower, digits = decimal),
      Upper = round(upper, digits = decimal),
      `Credible Interval` = str_c("[", Lower, ", ", Upper, "]")
    ) |>
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row, 2], "  ", model[row, 3])
}

form <- function(model_form) {
  dep <- as.character(model_form$formula[2])
  ind <- as.character(model_form$formula[3])

  str_c(dep, " ~ ", ind) |>
    str_replace_all(" ", "") |>
    str_replace_all("\\*", " $\\\\times$ ") |>
    str_replace_all("\\+", "&nbsp;+ ") |>
    str_replace_all("~", "$\\\\sim$ ")
}
```


# Introduction

<!-- intro --> 

[way to long, please chop down]
Learning language requires not just learning the facts of a language, but also learning how to use that language to communicate. One common test environment for language use is referential communication, the ability to give a description so that an interlocuter can pick out a target referent from a set of possibilities. Adults show sensitivity to both the visual context and their audience during referential communication, calibrating the type of description and the amount of information they provide to their beliefs about the interlocuters knowledge state. 

One test of referential communication skill is *iterated reference games* where a describer identifies abstract shapes from an array of images repeatedly to the same partner [@clark1986; @krauss1964; @hawkins2020b; @boyce2024]. Over repetition, features of the initial verbose descriptions are conventionalized as each pair comes to agree on a shared understanding of how to label each image. Success at this task requires mastery of a number of linguistic and communicative skills including producing adequate initial descriptions, monitoring for comprehension and asking for clarification, and appropriately using the shared conversation history to inform referring expressions in later rounds. 

All of these are skills that children must learn as part of their acquisition of language, but there is debate on the acquisition trajectories of different linguistic and communicative skills. Studying how children play iterated reference games can provide insight into the developmental trajectories of the ability to produce expressions to achieve joint understanding. 

A study on children's referential communication declared 4-5 year old preschoolers incapable of the task of child-child referential communication [@glucksberg1966]. In their paradigm, one child was given a set of 6 blocks in a specific order. Their task was to describe the images on the block so their partner could pick out their corresponding block. As children described and selected blocks, they stacked them on pegs, so that the order of blocks on the peg was a measure of correct matching. 4-5 year old children were successful on practice trials where the blocks had drawings of farm animals and they had visual access to each others blocks; however, younger children (3-4 year olds) were not even able to understand the instructions and complete the practice trials.  On the critcal trials, the 4-5 year old children were tested with abstract shapes on the blocks and no visual access to the other child's blocks. In this condition, even after multiple rounds with the same images, children were not able to produce referential descriptions that allowed for success at the matching task. 

Similar experiments with older children indicated a gradual improvement across age (up to the teen years) both at their initial accuracy and on their improvement over repetitions, although even the 9th grade sample was noticeably worse than their adult college student sample [@glucksberg1967; @krauss1969]. @glucksberg1966 attributed the young children's failures to the children’s use of idiosyncratic referring expressions unique to their own experiences, making it difficult for the pair to converge on shared descriptions. However, the complexity of the stacking paradigm and the large number of potential targets meant that this was not a clean test of children's ability to produce adequate referent expressions as the experiment had substantial task demands that could mask children's abilities. 

Since then, a number of studies have targeted specific skills needed for referential communication, including expectations around consistent labeling ("conversational pacts"), awareness of other's perspectives, and sensitivity to descriptive adequacy in varying contexts. A number of these studies have found roots of understanding emerging during hte preschool years, albeit with inconsistent expression. 

Young children show some sensitivity to the expectation that during cooperative communicate a person will likely re-use their own descriptions.  As listeners, preschoolers (3-5 year olds) are faster to select a target when it is referred to in a consistent way [@graham2014; @matthews2010]. However, this preference for familiar descriptions is applied regardless of whether they are said by the same person or a new person, and they sometimes verbally protesting the use of a new term ("That's a horse, not a pony!") [@matthews2010]. As the producers of descriptions, children show some partner-specificity, but are far from consistent. @koymen2014 had 4 and 6 year old children do a version of the paradigm from @brennan1996. Children used specific referring expressions ("woman's shoe") with one partner in a visual context of different types of shes. In later trials when only one shoe was present and thus a general expression like "shoe" was adequate, 6 year olds were somewhat more likely to continue using the specific term with the same partner than with a new partner, whereas 4 year olds used both specific and general expressions at the same rate regardless of partner. 

Expectations of consistency are entwined with being able to take the perspective of an interlocuter. Young children are notoriously ego-centric [@epley2004; TODO there are probably better things to cite here instead], but even preschoolers are able to take other's perspectives, especially when the are not under too much cognitive load [@sanjuan2015]. Across the 2-4 year olds range, children are developing sensitivity to what is given their interlocuter based on the discourse history and visual context available to their interlocuter [@matthews2006]. Older preschoolers are more likely to use more given forms such as pronouns when their interlocuter has more context and indefinite forms when their interlocuter has less context.  4-6 year old children are more likely to use a more specific reference expression with a size modifier when their partner can see the size competitor than when their partner cannot see the competitor, but children produce the modifier inconsistently even when it is necessary to distinguish the target [@nadig2002; @nilsen2009].

The skill children seem to struggle the most with is appropriately tailoring the specificity of their utterances to the visual context. 4 year olds showing some improvement after getting specific feedback that models appropriate descriptions, but still a lot of inconsistency [@matthews2012].  Children ages 4-8 often produce the same label for a target object regardless of whether the context is close or far, leading to descriptions that are underinformative for close contexts [@leung2024]. When children must pick out one of two very similar images, 4 and 5 year olds aren't good at mentioning the relevant features, although they do better when playing in an interactive game than when not [@grigoroglou2019]. By age 5, children are sensitive to utterances that are over- or under-informative, asking for clarification on some under-informative utterances and taking longer to make selections on over-informative utterances, although children still do not ask for clarification all the time [@morisseau2013]. 

A common thread between many studies in referential expression production is that children perform better when the cognitive load of the task is reduced, i.e. fewer distractor referents [@abbot-smith2016]. This suggests that tailored referential expression production is possible in children, but it is likely to be masked in situations that involve cognitive load. 

Since @glucksberg1966, only a few studies have revisited the question of how well children can put together different skills to communicate in an iterated reference game. @branigan2016 tested 72 8-10 year olds on iterated referential communication using a paradigm based on @wilkes-gibbs1992. In the training period, pairs of children matched tangrams in order from a pool of 8 images. Qualitatively, children on average showed the classic patterns of increasing accuracy, increasing speed, and shorter descriptions across repetitions. However, children's level of accuracy was far below what is typical for adults and varied dramatically from pair to pair. 

Some of the skills required in iterated reference games are communicative rather than purely linguistic. In @bohn2019, 4 and 6 year olds communicated target images from a pool of 5 images via a video link without audio. Children's comprehension was good and increased over repetitions, and children, especially the 6 year olds,  showed signs of agreeing on conventionalized gestures with their partner.  

A recent study on younger children examined children's abilities to play an iterated reference game with a parent. @leung2024 had 63 children ages 4-8 year olds play a matching game on tablets, where, on each trial, participants saw two images.  The describer's tablet had a box around one image and their task was to verbally describe the image so their partner could select the corresponding image. The target images were tangrams, with a total of 10 target images, which repeated across 4 blocks for a total of 40 trials per pair. In this task, even 4 year olds had an initial accuracy above 80% which rose to above 90% on the later repetitions. 

Given the potential for task demands in @glucksberg1966 and the level of success young children had with their parents at a simplified, less demanding paradigm, we revisit the question of children's ability to converge on appropriate referential expressions with each other.
In the present study, we re-examine young children's ability to establish effective referring expressions with each other in an iterated reference game using a simplified paradigm to reduce cognitive demands.

```{r interface, fig.env = "figure*", fig.pos = "t!", out.width="\\textwidth", fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Experimental Setup and Procedure. Panel A shows the experimental setup with the teller and guesser across the table from each other. Panel B shows the 4 possible targets; names for targets are for cross-reference with later figures only. Panel C shows the procedure for Experiment 1; within in critical block targets were ordered randomly. Panel D shows the procedure for Experiment 2. \\label{game}", cache=FALSE}

knitr::include_graphics("diagram.pdf")


# edit diagram at 
# https://docs.google.com/drawings/d/1gio1CNSedECJGrkrNDUi_AydPZcYzESfl4WhZD2l9Bc/edit?usp=sharing
```

# Experiment 1 Methods

(Note: we should talk about whether it makes more sense to do all the methods and then all the results versus the current expt 1 than expt 2 layout.)

Our goal for experiment 1 was to test young children's ability to coordinate on descriptions to abstract shapes that their partner could understand. Young children can be very sensitive to task demands and cognitive load that can hide early abilities [CITATION WANTED], so we adapted the experimental framework from @leung2024, but further simplified it by reducing the total pool of targets and the number of trials children completed. 

This experiment was pre-registered at https://osf.io/kcv8j. 

## Participants
4 and 5 year old children were recruited from a university nursery school during the school day. Children played with another child from the same class. Experiment 1 was conducted between June and August 2023. Pairs of children were included in analyses if they completed at least 8 of the 12 critical trials. We had 19 complete games and 1 incomplete, but included game. Of the 40 children, 21 were girls, and the median age was 57 months, with a range of 48-70 months. 

```{r, eval=F}
# demo <- read_csv(here("demographics.csv")) |>
#   filter(included == "x") |>
#   mutate(date_test = mdy(date_test), date_birth = mdy(date_birth)) |>
#   select(date_test, date_birth, gender) |>
#   mutate(
#     age = date_test - date_birth,
#     age = as.numeric(age) / 365.25 * 12
#   ) |> 
#   mutate(expt=ifelse(date_test>ymd("2024-01-01"), "expt2", "expt1")) |> 
#   group_by(expt) |> 
#   summarize(female=sum(gender=="female"),
#             total=n(),
#             median=median(age),
#             min=min(age),
#             max=max(age))
```


## Materials
For the target stimuli, we used four of the ten tangram images from @leung2024, chosen based on visual dissimilarity (Figure \ref{game}B). We coded the matching game using Empirica and hosted it on a lab server [@almaatouq2020]. We then accessed the game on the web on tablets that were locked in a kiosk mode so children could not navigate to other websites or applications during the game.

## Procedure
Once a pair of children agreed to play the game, a research assistant took them to a quiet testing room where the game was explained to them. Children were introduced to a stuffed animal "Smurfy" who wanted to play a matching game. Children sat across a table from each other, each with a tablet in front of them (Figure \ref{game}A). On each trial, one child saw two images, one of them in a black box, and was asked to "say what they saw" in the black box so their partner (and Smurfy) could tap the corresponding image. The guesser saw the same two images (in a randomized order). Upon tapping an image, both children received feedback in form of a smiley or frowny face and an audible sound. After each trial, children's roles switched. Children passed Smurfy back and forth to help them keep track of whether they were the "guesser" or "teller" on a given trial.

Children completed two warm-up trials with black and white images of familiar shapes, followed by 3 blocks of the 4 targets (Figure \ref{game}C). Targets were randomly paired with another of the critical images as the foil. 

The experimenters running the game did not volunteer descriptions, but did scaffold the interaction, prompting children to describe the images, and sometimes repeating children's statements. The entire interaction was video-recorded. 





## Data processing

Children's selections and the time to selection were recorded from the experiment software. Children's descriptions were transcribed from the video-recording, using Whisper [@radford2022] for the first pass and then hand-corrected by experimenters. Transcripts were hand-annotated for when each trial started, who said each line, and what referential descriptions were used. 

We excluded trials where the "teller" did not produce a description, or where all description was unintelligible and impossible to transcribe. After exclusions, we had `r clean_2 |> filter(!is.na(repNum)) |> nrow()` trials remaining. 

Statistical analyses were run in TODO CITE brms with weakly informative priors. We present the estimate and 95% credible intervals. 

# Experiment 1 Results

## Accuracy

```{r fig-accuracy, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="100%", fig.width=5, fig.height=3, fig.cap = "Children's accuracy at selecting the correct target over time. Experiment 1 had 3 blocks (12 total critical trials) and experiment 2 had 4 blocks (16 critical trials). Error bars are bootstrapped 95% CIs with a linear trend line overlaid. \\label{acc}" }
clean_2 |>
  filter(type != "practice") |>
  mutate(trial = trial - 3, expt = "Expt 2") |>
  bind_rows(clean_1 |> filter(type != "practice") |> mutate(trial = trial - 1, expt = "Expt 1")) |>
  ggplot(aes(x = trial, y = correct)) +
  stat_summary(aes(fill = type), fun.data = "mean_cl_boot", geom = "bar") +
  stat_summary(fun.data = "mean_cl_boot", geom = "linerange", color = "black") +
  scale_fill_manual(values = time_palette) +
  # geom_bar(position = position_dodge(.9), color = "black", fill = "#19ADDE", width = .7) +
  geom_smooth(method = "lm", color = "black") +
  # geom_text(aes(label = percent), hjust = 1.6, color = "white", size = 3) +
  xlab("Trial") +
  ylab("Accuracy") +
  scale_x_continuous(breaks = seq(1, 16, 4), expand = c(0, 0)) +
  scale_y_continuous(breaks = seq(0, 1, .2), expand = c(0, 0)) +
  geom_hline(yintercept = .5) +
  facet_grid(expt ~ .) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    strip.background = element_blank()
  )
```

```{r, eval=F}
acc_priors <- c(
  set_prior("normal(0,1)", class = "b"),
  set_prior("normal(0,1)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)

acc_mod_data_1 <- clean_1 |>
  mutate(
    correct.num = ifelse(correct == TRUE, 1, 0),
    trial.num = trial - 2
  ) |>
  filter(type != "practice")
acc_mod_1 <- brm(correct.num ~ trial.num + (trial.num | game) + (1 | target),
  family = bernoulli(link = "logit"),
  data = acc_mod_data_1,
  file = here(mod_loc, "acc_1.rds"),
  prior = acc_priors,
  control = list(adapt_delta = .95)
)
```

```{r}
acc_mod_1 <- read_rds(here(mod_results, "acc_1.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))

acc_form <- read_rds(here(mod_form, "acc_1.rds"))
```

Our primary measure of interest was whether children could accurately communicate the intended target, as prior work is often interpreted as indicating the children at kindergarten age cannot communicate about abstract shapes successfully [@glucksberg1966]. As shown in Figure \ref{acc}, children were above chance in their selections. To confirm this and test for any changes in accuracy over time, we fit a mixed effects model of accuracy (`r acc_form |> form()`). Children's accuracy was above chance (Odds Ratio: `r stats_text(acc_mod_1,1)`) and accuracy slightly increased over the game (OR of one trial later: `r stats_text(acc_mod_1, 2)`). 

## Speed

```{r, eval=F}
speed_priors <- c(
  set_prior("normal(60,100)", class = "Intercept"),
  set_prior("normal(0,20)", class = "b"),
  set_prior("normal(0,20)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)

speed_mod_data_1 <- clean_1 |>
  mutate(
    time.sec = time / 1000,
    trial.num = trial - 2
  ) |>
  filter(type != "practice")

speed_mod_1 <- brm(time.sec ~ trial.num + (trial.num | game) + (1 | target),
  data = speed_mod_data_1,
  file = here(mod_loc, "speed_1.rds"),
  prior = speed_priors,
  control = list(adapt_delta = .95)
)
```

```{r}
speed_mod_1 <- read_rds(here(mod_results, "speed_1.rds"))

speed_form <- read_rds(here(mod_form, "speed_1.rds"))
```

[less important, could drop] As another measure of children's performance, we looked at how long each trial took to see if children were getting faster over time. We ran a Bayesian mixed effects model of how long each trial took over time: `r speed_form |> form()`. The first trial critical trial averaged `r stats_text(speed_mod_1, 1)` seconds, and children got faster over time (`r stats_text(speed_mod_1, 2)`). 

## Description length


```{r, eval=F}
description_priors <- c(
  set_prior("normal(5,10)", class = "Intercept"),
  set_prior("normal(0,5)", class = "b"),
  set_prior("normal(0,5)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)

description_mod_data_1 <- clean_1 |>
  mutate(
    trial.num = trial - 2
  ) |>
  filter(type != "practice")

description_mod_1 <- brm(words ~ trial.num + (trial.num | game) + (1 | target),
  data = description_mod_data_1,
  file = here(mod_loc, "description_1.rds"),
  prior = speed_priors,
  control = list(adapt_delta = .95)
)
```

```{r description, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="100%", fig.width=5, fig.height=3, fig.cap = "Length of referential expression (in words) produced by the speaker each trial. Grey dots are individual data points, colored dots are per trial means with bootstrapped 95% CIs. \\label{length}" }
clean_2 |>
  filter(type != "practice") |>
  mutate(trial = trial - 3, expt = "Expt 2") |>
  bind_rows(clean_1 |> filter(type != "practice") |> mutate(trial = trial - 1, expt = "Expt 1")) |>
  ggplot(aes(x = trial, y = words, color = type)) +
  geom_jitter(alpha = .5, color = "grey") +
  stat_summary(fun.data = "mean_cl_boot") +
  scale_x_continuous(breaks = seq(1, 20, 1), expand = c(0, 0)) +
  scale_color_manual(values = time_palette) +
  geom_smooth(method = "lm", color = "black") +
  xlab("Trial") +
  ylab("Words") +
  facet_grid(expt ~ .) +
  theme(
    legend.position = "none",
    panel.grid = element_blank(),
    strip.background = element_blank()
  )
```




```{r}
description_mod_1 <- read_rds(here(mod_results, "description_1.rds"))

description_form <- read_rds(here(mod_form, "description_1.rds"))
```

In iterated reference games in adults, a canonical finding is that the length of descriptions goes from long to short over repeated references to the initially hard to describe shapes [@clark1986; @hawkins2020b; @boyce2024]. We looked at how long the descriptions the children used were to see if the same trend occurred. 
We ran a Bayesian mixed effects model of how long of a description the "teller" produced: `r description_form |> form()`. The initial length was `r stats_text(description_mod_1, 1)` and description length was relatively stable over time (`r stats_text(description_mod_1, 2)`, shown in Figure \ref{length}). How long of a description is initially warranted depends on how iconic or easily describable the shape is, as well as how large and close the contrast set is. In this case, the low number of options to distinguish and relatively easy to describe shapes may mean long initial descriptions are less necessary. (The adult controls in @leung2024 use shorter initial descriptions than adults in studies with larger arrays of harder to distinguish images.) However, young children may also choose to provide shorter descriptions than adults would, and young children may accept shorter descriptions as adequate whereas adults may ask for more information to increase their confidence level before making a guess. 

## Convergence 

```{r}
conv_priors <- c(
  set_prior("normal(.5,.2)", class = "Intercept"),
  set_prior("normal(0,.1)", class = "b"),
  set_prior("normal(0,.05)", class = "sd")
)

sim_across_between_data_1 <- sims_1 |>
  mutate(same_game = case_when(
    game1 == game2 ~ 1,
    T ~ 0
  )) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, 1, 0))


sim_across_between_mod_1 <- brm(sim ~ same_game + same_speaker + (1 | target),
  data = sim_across_between_data_1,
  file = here(mod_loc, "sim_across_between_1.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)
```

```{r sims, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="100%", fig.width=5, fig.height=3, fig.cap = "Semantic similarity between referential descriptions from the speaker to the same target under different circumstances. Different games refers to similarities across two speakers from different games, same game to similarities across the two participants in one game, and same speaker to descriptions from the same person in different blocks. Dots are means and lines are bootstrapped 95% CIs.  \\label{sim}" }
sims_2 |>
  mutate(source = case_when(
    speaker1 == speaker2 ~ "same speaker",
    game1 == game2 ~ "same game",
    T ~ "different games"
  )) |>
  mutate(expt = "Expt 2") |>
  bind_rows(sims_1 |>
    mutate(source = case_when(
      speaker1 == speaker2 ~ "same speaker",
      game1 == game2 ~ "same game",
      T ~ "different games"
    )) |> mutate(expt = "Expt 1")) |>
  ggplot(aes(x = source, y = sim, color = target1)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
  labs(y = "Cosine similarity", x = "Comparing two utterances from ...", color = "target image") +
  facet_grid(expt ~ .) +
  scale_color_solarized() +
  theme(
    legend.position = "bottom",
    panel.grid = element_blank(),
    strip.background = element_blank()
  )
```


```{r}
sim_across_between_1_results <- read_rds(here(mod_results, "sim_across_between_1.rds"))

sim_across_between_form <- read_rds(here(mod_form, "sim_across_between_1.rds"))
```


```{r, include=F}
sims_1 |>
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == 3) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, "same speaker", "different speaker")) |>
  ggplot(aes(as.character(earlier), sim, color = target1)) +
  geom_point(alpha = .1, position = position_dodge(width = .2)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
  facet_wrap(~same_speaker) +
  labs(x = "Earlier block to last block", y = "cosine similarity", color = "target") +
  theme(legend.position = "bottom")
```

```{r include=F}
sims_1 |>
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == earlier + 1) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, "same speaker", "different speaker")) |>
  ggplot(aes(as.character(earlier), sim, color = target1)) +
  geom_point(alpha = .1, position = position_dodge(width = .2)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
  facet_wrap(~same_speaker) +
  labs(x = "Earlier block to *next* block", y = "cosine similarity", color = "target") +
  theme(legend.position = "bottom")
```

```{r, include=F}
sims_1 |>
  filter(game1 != game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == earlier) |>
  ggplot(aes(as.character(earlier), sim, color = target1)) +
  geom_point(alpha = .01, position = position_dodge(width = .2)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
  labs(x = "Cross game similarity in block ...", y = "cosine similarity", color = "target") +
  theme(legend.position = "bottom")
```

While description length is used as a proxy for measuring convention formation, better measurements for convergence look at the actual content of the utterances, which does not always track description length [@boyce2024]. Following @boyce2024, we use Sentence-BERT to embed the descriptions in a semantic vector space, and then use the cosine between embeddings as a measure of semantic similarity between descriptions. We compared the semantic similarities between descriptions of the same target based on who produced the description. Our question was whether the two children within the same game produced descriptions that are more similar to each other than two children in different games. 

As shown in Figure \ref{sim}, different children in the same game produced more similar descriptions than children in different games, although the descriptions were less similar than descriptions from the same child in different rounds. We modeled this as `r sim_across_between_form |> form()`. Utterances were more similar if they came from the same partnership (`r sim_across_between_1_results |> stats_text(2,3)`) and were slightly more similar still if they came from the same person with the partnership (`r sim_across_between_1_results |> stats_text(3,3)`). The big differences in descriptions between games compared to within games is a measure of partner sensitivity.

# Experiment 1 Discussion

In the first experiment, we adapted the paradigm of @leung2024 for pairs of children, taking an already simple set up and making it shorter. Our goal was to see if young children were at all able to provide descriptions to each other adequate to identify abstract figures. so children recieved a lot of scaffolding around the experimental interaction. Sometimes, this included experimenter echoing children's descriptions which could potentially influence children's responses. In Experiment 2, we repeated the same paradigm, with tighter experimenter controls and a larger sample size. 

# Experiment 2 Methods

As Experiment 2 was very similar to Experiment 1, we focus on the changes made compared to Experiment 1. Experiment 2 was pre-registered at https://osf.io/y2dax. 

## Participants
Experiment 2 was run between March and August of 2024, at the same university preschool as experiment 1. No children participated in both experiments. 30 pairs of children completed all 16 critical trials, and 1 pair of children completed between 8 and 16 critical trials. Our target age range was 4 and 5 year olds, but one almost 4-year-old was unintentionally included. Of the 62 children, 30 were girls, and the children had a median age of 56 months, and a range of 45-69 months. 

## Materials
The same 4 critical images were used as in experiment 1, although this time, children saw these images 4 times. In response to some children struggling with the abrupt switch from nameable to non-nameable shapes, we introduced more practice trials for experiment 2. We used a total of 4 practice trials to provide a gradient from more recognizable shapes to less recognizable, blockier shapes (Figure \ref{game}D). 

## Procedure
The procedure was much the same (Figure \ref{game}D). We added an initial "bubble popping" exercise to give children practice with how to tap the tablet appropriately (this was an issue for some children in the first experiment).  The experimental script was fully written out so children all received the same instructions. We wrote up contingency statements that the experimenter could use to prompt children who were not giving descriptions or making selections. Experimenters would help with game mechanics such as who's turn it was to tell and who should press the screen to move the game along, but would not provide or repeat any content about the images, what to ask, or whether a description was adequate. 

## Data processing
Data was processed in the same way as experiment 1. After excluding trials where children did not give a description or where the experimenter echoed a child's description, we had `r clean_2 |> filter(!is.na(repNum)) |> nrow()` trials total. 

# Experiment 2 Results

We report the same set of analyses and model results as in Experiment 1 as well as additional analyses of how the semantic content of children's descriptions changes over time. 

## Accuracy



```{r, eval=F}
acc_priors <- c(
  set_prior("normal(0,1)", class = "b"),
  set_prior("normal(0,1)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)

acc_mod_data <- clean_2 |>
  mutate(
    correct.num = ifelse(correct == TRUE, 1, 0),
    trial.num = trial - 4
  ) |>
  filter(type != "practice")
acc_mod <- brm(correct.num ~ trial.num + (trial.num | gameId) + (1 | target),
  family = bernoulli(link = "logit"),
  data = acc_mod_data,
  file = here(mod_loc, "acc_2.rds"),
  prior = acc_priors,
  control = list(adapt_delta = .95)
)
```

```{r}
acc_mod_2 <- read_rds(here(mod_results, "acc_2.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))
```

As in Experiment 1, in Experiment 2, children's accuracy was above chance (Odds Ratio: `r stats_text(acc_mod_2,1)`) and accuracy slightly increased over the course of the game (OR of one trial later: `r stats_text(acc_mod_2, 2)`, Figure \ref{acc}). This confirms that children are able to communicate with each other about these abstract shapes. 

## Speed

```{r}
speed_priors <- c(
  set_prior("normal(60,100)", class = "Intercept"),
  set_prior("normal(0,20)", class = "b"),
  set_prior("normal(0,20)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)

speed_mod_data_2 <- clean_2 |>
  mutate(
    time.sec = time / 1000,
    trial.num = trial - 2
  ) |>
  filter(type != "practice")

speed_mod_2 <- brm(time.sec ~ trial.num + (trial.num | gameId) + (1 | target),
  data = speed_mod_data_2,
  file = here(mod_loc, "speed_2.rds"),
  prior = speed_priors,
  control = list(adapt_delta = .95)
)
```

```{r}
speed_mod_2 <- read_rds(here(mod_results, "speed_2.rds"))
```

In Experiment 2, the first critical trial averaged `r stats_text(speed_mod_2, 1)` seconds, and children got faster over time (`r stats_text(speed_mod_2, 2)`). Children were initially faster in Experiment 2 than Experiment 1, possibly due to the increased number of practice trials and pre-training on how to press the screens. 

## Description length

```{r, eval=F}
description_priors <- c(
  set_prior("normal(5,10)", class = "Intercept"),
  set_prior("normal(0,5)", class = "b"),
  set_prior("normal(0,5)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)

description_mod_data_2 <- clean_2 |>
  mutate(
    trial.num = trial - 2
  ) |>
  filter(type != "practice")

description_mod_2 <- brm(words ~ trial.num + (trial.num | gameId) + (1 | target),
  data = description_mod_data_2,
  file = here(mod_loc, "description_2.rds"),
  prior = speed_priors,
  control = list(adapt_delta = .95)
)
```


```{r}
description_mod_2 <- read_rds(here(mod_results, "description_2.rds"))
```

The average length of descriptions on the first trial was `r stats_text(description_mod_2, 1)` words and description length was relatively stable over time (`r stats_text(description_mod_2, 2)`, Figure \ref{length}). This is comparable to Experiment 1, again finding that children produce short utterances without much change in length over time. 
Children used a wide range of descriptions successfully, and some example descriptions are shown in Table \ref{example}. Often children would use the same description as their partner, although there were some transitions such as from "a person holding a flute" to "a person holding a trumpet".

(not sure how much to say or where to put)
Pairs of children varied significantly in how well they could scaffold their own interaction versus needed reminders from experimenters about the structure of the game. 
In one game, the experimenter provided no input after the practice trials because the children rapidly took turns producing referring expressions and selecting the targets. Their advantage could partially be due to being best friends with each other, who may have been more comfortable with each other and had more common ground to start with. All children were paired with another child from the same classroom they were willing to play with, but friendship levels varied. 

Some children asked clarifying questions of their partner, but knowing how much information to provide was not always consistent. In one game, child A described the figure as "A human", prompting child B to note "There's two humans." Later in the game, child B used the description "A human", leading child A to ask "Which one?", which child B clarified with"The one that is walking". This anecdote illustrates how emerging abilities can be inconsistent -- finding a description inadequate as a guesser does not always translate into providing a more informative description as a teller. 




```{=latex}

\begin{table}
	\caption{Example descriptions children used for different tangrams. TODO may want to shorter or pair with the tangram images}
		\label{example}
	\begin{tabular}[H]{p{22em}}
		Descriptions \\
		\hline
		%hold
		"Hold":\\
		$\bullet$ person\\
		$\bullet$ a person holding a sandwich\\
		$\bullet$ a people carrying a box of dirt\\
		$\bullet$ a monster\\
		$\bullet$ someone holding a plate and giving it to a restaurant and has watermelon\\
		\hline
	"Jump":\\
		$\bullet$ vampire\\
		$\bullet$ hopping\\
		$\bullet$ a person flying\\
		$\bullet$ somebody skydiving, not in the airplane\\
		$\bullet$ a person\\
		$\bullet$ a kite\\
		$\bullet$ a triangle with a head on it with feet\\
		\hline
		"Swim":\\
		$\bullet$ racecar\\
		$\bullet$ airplane\\
		$\bullet$ alligator\\
		$\bullet$ a person fell down\\
		$\bullet$ a boat\\
		$\bullet$ a person that's in a race car that has one triangle and two triangles\\
		\hline
		"Walk":\\
		$\bullet$ person\\
		$\bullet$ a person walking\\
		$\bullet$ a person looking down\\
		$\bullet$ a people, but it doesn't have any arms\\
		\hline
	\end{tabular}
\end{table}

```



## Convergence 


```{r}
conv_priors <- c(
  set_prior("normal(.5,.2)", class = "Intercept"),
  set_prior("normal(0,.1)", class = "b"),
  set_prior("normal(0,.05)", class = "sd")
)

sim_across_between_data_2 <- sims_2 |>
  mutate(same_game = case_when(
    game1 == game2 ~ 1,
    T ~ 0
  )) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, 1, 0))


sim_across_between_mod_2 <- brm(sim ~ same_game + same_speaker + (1 | target),
  data = sim_across_between_data_2,
  file = here(mod_loc, "sim_across_between_2.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)

sim_to_last_data_2 <- sims_2 |>
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == 4) |>
  mutate(
    same_speaker = ifelse(speaker1 == speaker2, 1, 0),
    earlier_block.num = earlier - 1
  )

sim_to_last_mod_2 <- brm(sim ~ earlier_block.num + same_speaker + (1 | game1) + (1 | target),
  data = sim_to_last_data_2,
  file = here(mod_loc, "sim_to_last_2.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)

sim_to_next_data_2 <- sims_2 |>
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == earlier + 1) |>
  mutate(
    same_speaker = ifelse(speaker1 == speaker2, 1, 0),
    earlier_block.num = earlier - 1
  )

sim_to_next_mod_2 <- brm(sim ~ earlier_block.num + same_speaker + (1 | game1) + (1 | target),
  data = sim_to_next_data_2,
  file = here(mod_loc, "sim_to_next_2.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)

sim_across_data_2 <- sims_2 |>
  filter(game1 != game2) |>
  filter(block1 == block2) |>
  mutate(block.num = block1 - 1)

sim_across_mod_2 <- brm(sim ~ block.num + (1 | target),
  data = sim_across_data_2,
  file = here(mod_loc, "sim_across_2.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)
```


```{r sim2, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="100%", fig.width=5, fig.height=3, fig.cap = "Semantic similarity between earlier blocks (1-3) with last block (4) for descriptions to the same image within the same group. SImilarity measured as cosine similarity between S-BERT embeddings of referential descriptions. Heavy dots are means with bootstrapped 95% CIs; light dots are individual values. \\label{tolast}" }
sims_2 |>
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == 4) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, "same speaker", "different speaker")) |>
  ggplot(aes(as.character(earlier), sim, color = target1)) +
  geom_point(alpha = .1, position = position_dodge(width = .2)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
  facet_wrap(~same_speaker) +
  scale_color_solarized() +
  labs(x = "Earlier block to last block", y = "cosine similarity", color = "target") +
  theme(legend.position = "bottom")
```

```{r, include=F}
sims_2 |>
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == earlier + 1) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, "same speaker", "different speaker")) |>
  ggplot(aes(as.character(earlier), sim, color = target1)) +
  geom_point(alpha = .1, position = position_dodge(width = .2)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
  facet_wrap(~same_speaker) +
  labs(x = "Earlier block to *next* block", y = "cosine similarity", color = "target") +
  theme(legend.position = "bottom")
```

```{r, include=F}
sims_2 |>
  filter(game1 != game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == earlier) |>
  ggplot(aes(as.character(earlier), sim, color = target1)) +
  geom_point(alpha = .01, position = position_dodge(width = .2)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
  labs(x = "Cross game similarity in block ...", y = "cosine similarity", color = "target") +
  theme(legend.position = "bottom")
```


```{r}
sim_across_between_2_results <- read_rds(here(mod_results, "sim_across_between_2.rds"))

sim_across_between_form <- read_rds(here(mod_form, "sim_across_between_2.rds"))

sim_across_2_results <- read_rds(here(mod_results, "sim_across_2.rds"))

sim_across_form <- read_rds(here(mod_form, "sim_across_2.rds"))

sim_to_next_2_results <- read_rds(here(mod_results, "sim_to_next_2.rds"))

sim_to_next_form <- read_rds(here(mod_form, "sim_to_next_2.rds"))

sim_to_last_2_results <- read_rds(here(mod_results, "sim_to_last_2.rds"))

sim_to_last_form <- read_rds(here(mod_form, "sim_to_last_2.rds"))
```

To look at semantic distance between utterances, we again operationalize similarity between pairs of utterances as the cosine similarity between their Sentence-BERT embeddings [@reimers2019]. 

As a coarse comparison, we repeated the analysis from Experiment 1. Utterances were more similar if they came from the same partnership (`r sim_across_between_2_results |> stats_text(2,3)`) and were slightly more similar still if they came from the same person with the partnership (`r sim_across_between_2_results |> stats_text(3,3)`). 

The greater number of trials in Experiment 2 makes it possible to look for changes over time that could be indicative of convergence to shared descriptions within a game and divergence between games. 

To look for convergence to shared descriptions within games, we compared the utterances from the first three blocks to the descriptions in the last block: `r sim_to_last_form |> form()`. Over the first three blocks, descriptions become increasingly similar to the last block description (`r sim_to_last_2_results |> stats_text(2,3)`). Descriptions are more similar to the last block if they come from the same child who gave the description in the last block (`r sim_to_last_2_results |> stats_text(3,3)`). 

Another way to look for convergence is to look at the semantic distance between utterances in adjacent blocks: `r sim_to_next_form |> form()`. Although over time descriptions do get more similar to the last block utterance, the distance between adjacent block utterances is relatively constant: `r sim_to_next_2_results |> stats_text(2,3)`. 

As each partnership converges to their shared nicknames, partnerships often diverge from one another as groups focus on distinct aspects of the image. We tested whether descriptions in different games to the same target diverged over time: `r sim_across_form |> form()`. As the games progress, descriptions from different games became slightly further apart in semantic space (`r sim_across_2_results |> stats_text(2,3)`). 

# Post hoc results

## Meta-analytic placeholder 

Might want to split out and incorporate in along with expt 2 analyses?

```{r, eval=F}

acc_priors <- c(
  set_prior("normal(0,1)", class = "b"),
  set_prior("normal(0,1)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)


acc_mod_data_meta <-  clean_1 |>
  mutate(
    correct.num = ifelse(correct == TRUE, 1, 0),
    trial.num = trial - 2
  ) |>
  filter(type != "practice") |> mutate(gameId=game) |> bind_rows(clean_2 |>
  mutate(
    correct.num = ifelse(correct == TRUE, 1, 0),
    trial.num = trial - 4
  ) |>
  filter(type != "practice"))

acc_mod_both <- brm(correct.num ~ trial.num + (trial.num | gameId) + (1 | target),
  family = bernoulli(link = "logit"),
  data = acc_mod_data_meta,
  file = here(mod_loc, "acc_meta.rds"),
  prior = acc_priors,
  control = list(adapt_delta = .95)
)

```


```{r, eval=F}
description_priors <- c(
  set_prior("normal(5,10)", class = "Intercept"),
  set_prior("normal(0,5)", class = "b"),
  set_prior("normal(0,5)", class = "sd"),
  set_prior("lkj(1)", class = "cor")
)

description_mod_data_meta <- clean_1 |>
  mutate(
    trial.num = trial - 2
  ) |>
  filter(type != "practice")|> mutate(gameId=game) |> bind_rows(
 clean_2 |>
  mutate(
    trial.num = trial - 2
  ) |>
  filter(type != "practice"))

description_mod_meta <- brm(words ~ trial.num + (trial.num | gameId) + (1 | target),
  data = description_mod_data_meta,
  file = here(mod_loc, "description_meta.rds"),
  prior = speed_priors,
  control = list(adapt_delta = .95)
)

```

```{r, eval=F}
conv_priors <- c(
  set_prior("normal(.5,.2)", class = "Intercept"),
  set_prior("normal(0,.1)", class = "b"),
  set_prior("normal(0,.05)", class = "sd")
)

sim_across_between_data_2 <- sims_2 |>
  mutate(same_game = case_when(
    game1 == game2 ~ 1,
    T ~ 0
  )) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, 1, 0))

sim_across_between_data_1 <- sims_1 |>
  mutate(same_game = case_when(
    game1 == game2 ~ 1,
    T ~ 0
  )) |>
  mutate(same_speaker = ifelse(speaker1 == speaker2, 1, 0))

sim_across_between_data_meta <- sim_across_between_data_2 |> bind_rows(sim_across_between_data_1)

sim_across_between_mod_meta <- brm(sim ~ same_game + same_speaker + (1 | target),
  data = sim_across_between_data_meta,
  file = here(mod_loc, "sim_across_between_meta.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)



sim_to_next_data_meta <- sims_2 |> bind_rows(sims_1) |> 
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  filter(later == earlier + 1) |>
  mutate(
    same_speaker = ifelse(speaker1 == speaker2, 1, 0),
    earlier_block.num = earlier - 1
  )

sim_to_next_mod_meta <- brm(sim ~ earlier_block.num + same_speaker + (1 | game1) + (1 | target),
  data = sim_to_next_data_meta,
  file = here(mod_loc, "sim_to_next_meta.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)



```



```{r}
acc_mod_meta <- read_rds(here(mod_results, "acc_meta.rds")) |> mutate(across(c(`Estimate`, `lower`, `upper`), ~ exp(.)))

description_mod_meta <- read_rds(here(mod_results, "description_meta.rds"))

sim_across_between_mod_meta <- read_rds(here(mod_results, "sim_across_between_meta.rds"))

sim_to_next_mod_meta <- read_rds(here(mod_results, "sim_to_next_meta.rds"))
```

As the two experiments were similar to one another, we re-run models pooling across the two experiments. 
Pooling the two experiments, children's accuracy was above chance (Odds Ratio: `r stats_text(acc_mod_meta,1)`) and accuracy slightly increased over the course of the game (OR of one trial later: `r stats_text(acc_mod_meta, 2)`. 

The average length of descriptions on the first trial was `r stats_text(description_mod_meta, 1)` words and description length was relatively stable over time (`r stats_text(description_mod_meta, 2)`, Figure \ref{length}).

Utterances were more similar if they came from the same partnership (`r sim_across_between_mod_meta |> stats_text(2,3)`) and were slightly more similar still if they came from the same person with the partnership (`r sim_across_between_mod_meta |> stats_text(3,3)`).
Since the two expeirments had different length games, we do not want to pool them in comparing to the last block, but we can pool them comparing to the next block. 

 The distance between adjacent block utterances is relatively constant: `r sim_to_next_mod_meta |> stats_text(2,3)`. 

Query -- I did not include experiment # as a random effect here, and maybe should have? I can rerun if we decide we want this analysis and think expt # as a random effect with game nested within it would be useful. 

## Accuracy is predictive of similarity to next 


```{r}
# try visual first 

acc_sim_1 <- clean_1 |>
  filter(type != "practice") |> mutate(game1=game) |> 
  mutate(correct=ifelse(correct, 1,0),
         earlier_trial=trial+2) |> 
  select(earlier_trial, target, correct, game1)

acc_sim_2 <- clean_2 |>
  filter(type != "practice") |> select(earlier_trial=trial, target, correct, game1=gameId)

sim_acc_2 <- sims_2 |> 
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  mutate(earlier_trial = ifelse(trial1 > trial2, trial2, trial1)) |>
  filter(later == earlier + 1) |>
  mutate(
    same_speaker = ifelse(speaker1 == speaker2, 1, 0),
    earlier_block.num = earlier - 1
  ) |> 
  select(earlier_trial, target, game1, earlier, later, sim, earlier_block.num, same_speaker) |> 
  left_join(acc_sim_2)

sim_acc_1 <- sims_1 |> 
  filter(game1 == game2) |>
  mutate(later = ifelse(block1 > block2, block1, block2), earlier = ifelse(block1 > block2, block2, block1)) |>
  mutate(earlier_trial = ifelse(trial1 > trial2, trial2, trial1)) |>
  filter(later == earlier + 1) |>
  mutate(
    same_speaker = ifelse(speaker1 == speaker2, 1, 0),
    earlier_block.num = earlier - 1
  ) |> 
  select(earlier_trial, target, game1, earlier, later, sim, earlier_block.num, same_speaker) |> 
  left_join(acc_sim_1)

#ggplot(sim_acc_1, aes(x=earlier, y=sim, color=as.factor(correct)))+geom_point(alpha=.4, position=position_dodge(.4))+stat_summary()

#ggplot(sim_acc_2, aes(x=earlier, y=sim, color=as.factor(correct)))+geom_point(alpha=.4, position=position_dodge(.4))+stat_summary()

```

```{r, eval=F}
conv_priors <- c(
  set_prior("normal(.5,.2)", class = "Intercept"),
  set_prior("normal(0,.1)", class = "b"),
  set_prior("normal(0,.05)", class = "sd")
)
sim_acc_to_next_data <- sim_acc_1 |> bind_rows(sim_acc_2)
sim_acc_to_next_mod_meta <- brm(sim ~ earlier_block.num*correct + same_speaker*correct + (1 | game1) + (1 | target),
  data = sim_acc_to_next_data,
  file = here(mod_loc, "sim_acc_to_next_meta.rds"),
  prior = conv_priors,
  control = list(adapt_delta = .95)
)

# more stickiness if correct, no clear interactions 
# being correct has a similar size effect to same speaker
```

```{r}
sim_acc_to_next_mod_meta <- read_rds(here(mod_results, "sim_acc_to_next_meta.rds"))
sim_acc_to_next_form <- read_rds(here(mod_form, "sim_acc_to_next_meta.rds"))

```

As a post-hoc measure, we look at whether descriptions that elicit correct selections have more staying power than descriptions that do not elicit correct selections. Here we operationalized "staying power" as similarity to the next block utterance, and we model with `r form(sim_acc_to_next_form)`. Correct utterances have an increase in similarity with the next block by `r stats_text(sim_acc_to_next_mod_meta, 2, 3)` with no substantial interaction with block number or same speaker. Numerically, the size of the boost for being correct is similar to the size of the boost from coming form the same speaker `r stats_text(sim_acc_to_next_mod_meta, 6,3)`. 







# General Discussion

Across 2 experiments and 51 pairs of 4 and 5 year old children, we tested how well children were at producing referential expressions to allow their partner to find a matching abstract shape. Children varied substantially in what sorts of descriptions they produced, but overall accuracy was high (NUMBER), indicating that children were generally able to produce adequate descriptions. Additionally, children's utterances showed signs of converging toward conceptual pacts.  While this task is substantially scaled down relative to measures used for adult competence, and children do not display all the typical trends (i.e no sign of shortening of referential expression), it does suggest that the relevant communication skills are present at least in rudimentary form by the end of the preschool years. 

At least some preschoolers, in an environment with low task demands and support for understanding the structure of the task, can succeed at iterated referential communication. Our task is limited by the non-representative population of children at university nursery schools who participated, and by a limited set of target images. This set of tangram images may be easier to distinguish and refer to than some sets used with adults, leading to overall shorter utterances. We specifically targeted children's abilities to construct of referring expressions that can be jointly understood. Children were provided scaffolding around the larger coordination problems of taking turns nad talking to their partner. 

In the broader picture of language acquisition, there's debate over whether children learn the facts of their language first, followed much later, but pragmatic and communicative competency (CITATIONS), or whether sensitivity to communicative intent is an early emerging skill that develops in parallel with linguistic knowledge and may bootstrap language learning (CITATIONS). The findings in the current work are most consistent with a gradual development of children's communicative and linguistic skills, where the skills emerge early and then are refined over time, as children's cogntive capacities increase. At ages 4-5 years old, children are able to use their linguistic skills communicatively, even as their utterances are not fully adult-like in form. 


<!--# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.-->

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
